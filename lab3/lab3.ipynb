{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO22iCIgygs7"
      },
      "source": [
        "# ZSL-KG and Nayak Experiment Set uup\n",
        "\n",
        "1. pip install gdown\n",
        "2. clone zsl and nayak libs\n",
        "3. install requirements \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKPqMc8AydK_",
        "outputId": "9a4f273b-f857-45df-b6a8-d721af871a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Cloning into 'nayak-tmlr22-code'...\n",
            "remote: Enumerating objects: 189, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 189 (delta 52), reused 173 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (189/189), 2.16 MiB | 21.65 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ],
      "source": [
        "# clone nayak first, since it's going to be our main experiment base\n",
        "! pip install gdown\n",
        "! git clone https://github.com/BatsResearch/nayak-tmlr22-code.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgY53pZEuh9R",
        "outputId": "f6bfbecd-1721-4820-f7ac-453dff84cf6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nayak-tmlr22-code\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 28.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: alabaster==0.7.12 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 1)) (0.7.12)\n",
            "Collecting allennlp==0.9.0\n",
            "  Downloading allennlp-0.9.0-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs==20.2.0\n",
            "  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Babel==2.8.0\n",
            "  Downloading Babel-2.8.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 5)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.9.3\n",
            "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.8/115.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blis==0.2.4\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3==1.15.16\n",
            "  Downloading boto3-1.15.16-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore==1.18.16\n",
            "  Downloading botocore-1.18.16-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2020.6.20\n",
            "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 12)) (7.1.2)\n",
            "Collecting conllu==1.3.1\n",
            "  Downloading conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting cymem==2.0.3\n",
            "  Downloading cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (32 kB)\n",
            "Collecting dataclasses==0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 17)) (4.4.2)\n",
            "Collecting docutils==0.16\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 19)) (0.5.3)\n",
            "Collecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting flaky==3.7.0\n",
            "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting Flask==1.1.2\n",
            "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Flask-Cors==3.0.9\n",
            "  Downloading Flask_Cors-3.0.9-py2.py3-none-any.whl (14 kB)\n",
            "Collecting ftfy==5.8\n",
            "  Downloading ftfy-5.8.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gevent==20.9.0\n",
            "  Downloading gevent-20.9.0-cp37-cp37m-manylinux2010_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 28)) (2.10)\n",
            "Collecting imagesize==1.2.0\n",
            "  Downloading imagesize-1.2.0-py2.py3-none-any.whl (4.8 kB)\n",
            "Collecting importlib-metadata==2.0.0\n",
            "  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting iniconfig==1.0.1\n",
            "  Downloading iniconfig-1.0.1-py3-none-any.whl (4.2 kB)\n",
            "Collecting ipython==7.18.1\n",
            "  Downloading ipython-7.18.1-py3-none-any.whl (786 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.5/786.5 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 33)) (0.2.0)\n",
            "Requirement already satisfied: itsdangerous==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 34)) (1.1.0)\n",
            "Collecting jedi==0.17.2\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Jinja2==2.11.2\n",
            "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath==0.10.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting joblib==0.17.0\n",
            "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.5/301.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonnet==0.16.0\n",
            "  Downloading jsonnet-0.16.0.tar.gz (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.0/257.0 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpickle==1.4.1\n",
            "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
            "Collecting kiwisolver==1.2.0\n",
            "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting matplotlib==3.3.2\n",
            "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting murmurhash==1.0.2\n",
            "  Downloading murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (19 kB)\n",
            "Collecting networkx==2.5\n",
            "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 47)) (1.21.6)\n",
            "Collecting numpydoc==1.1.0\n",
            "  Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set==4.0.2\n",
            "  Downloading ordered-set-4.0.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging==20.4\n",
            "  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pandas==1.1.3\n",
            "  Downloading pandas-1.1.3-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parsimonious==0.8.1\n",
            "  Downloading parsimonious-0.8.1.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting parso==0.7.1\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 55)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 56)) (0.7.5)\n",
            "Collecting Pillow==7.2.0\n",
            "  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plac==0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pluggy==0.13.1\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting preshed==2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m468.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit==3.0.8\n",
            "  Downloading prompt_toolkit-3.0.8-py3-none-any.whl (355 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.5/355.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.13.0\n",
            "  Downloading protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess==0.6.0\n",
            "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting py==1.9.0\n",
            "  Downloading py-1.9.0-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pygments==2.7.1\n",
            "  Downloading Pygments-2.7.1-py3-none-any.whl (944 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.7/944.7 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==6.1.1\n",
            "  Downloading pytest-6.1.1-py3-none-any.whl (272 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.2/272.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-transformers==1.1.0\n",
            "  Downloading pytorch_transformers-1.1.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2020.1\n",
            "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.2/510.2 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses==0.12.0\n",
            "  Downloading responses-0.12.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting s3transfer==0.3.3\n",
            "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.5/69.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.43\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.8/883.8 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.5.2\n",
            "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.9/25.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 79)) (1.15.0)\n",
            "Collecting snowballstemmer==2.0.0\n",
            "  Downloading snowballstemmer-2.0.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve==2.0.1\n",
            "  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
            "Collecting spacy==2.1.9\n",
            "  Downloading spacy-2.1.9-cp37-cp37m-manylinux1_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Sphinx==3.2.1\n",
            "  Downloading Sphinx-3.2.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp==1.0.2\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-devhelp==1.0.2\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp==1.0.3\n",
            "  Downloading sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath==1.0.1\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting sphinxcontrib-qthelp==1.0.3\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-serializinghtml==1.1.4\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlparse==0.4.1\n",
            "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting srsly==1.0.2\n",
            "  Downloading srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.5/185.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX==2.1\n",
            "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.8/308.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thinc==7.0.8\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting tokenizers==0.8.1rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toml==0.10.1\n",
            "  Downloading toml-0.10.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.8/748.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.50.2\n",
            "  Downloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets==5.0.4\n",
            "  Downloading traitlets-5.0.4-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==3.3.1\n",
            "  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions==3.7.4.3\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting Unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.3/238.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3==1.25.10\n",
            "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.6/127.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wasabi==0.8.0\n",
            "  Downloading wasabi-0.8.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 106)) (0.2.5)\n",
            "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r zsl-kg-requirements.txt (line 107)) (1.0.1)\n",
            "Collecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting word2number==1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zipp==3.3.0\n",
            "  Downloading zipp-3.3.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting zope.event==4.5.0\n",
            "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface==5.1.2\n",
            "  Downloading zope.interface-5.1.2-cp37-cp37m-manylinux2010_x86_64.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.3/237.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet>=0.4.17 in /usr/local/lib/python3.7/dist-packages (from gevent==20.9.0->-r zsl-kg-requirements.txt (line 26)) (1.1.3.post0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent==20.9.0->-r zsl-kg-requirements.txt (line 26)) (57.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r zsl-kg-requirements.txt (line 46)) (2022.6.2)\n",
            "Building wheels for collected packages: ftfy, future, jsonnet, nltk, ordered-set, overrides, parsimonious, sacremoses, wget, word2number\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-py3-none-any.whl size=45633 sha256=3e0164c2026eb7cdf779657bbd349dcd15e1283c43a5152ef75d25d4704490b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/f3/e0/77d88809ab33c408fbb4033c3d4ad624fca457fbeae34e1432\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=66ce0454a4e5abe8adfc14011bc59d54fbea8e0dd7690d3385d67b4167f5dbc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/3c/b4/7132d27620dd551cf00823f798a7190e7320ae7ffb71d1e989\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp37-cp37m-linux_x86_64.whl size=3322331 sha256=bda14b747c576f1ee8e35b7bd25c355c69e4c6205e0225c16dc792ebc6ae912d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/22/e0/0bd80e5ebde2e44f99f2c6dc1de44d14b920a7c30a79dd4d3d\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434692 sha256=4e66e068213a97c208e4c7cab1f0272923b0cde55cf863bfd5c1188b56da35e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/59/cf/f7a731f600bcb19a6c61225ff7feb4ed00f2701446fdf51b07\n",
            "  Building wheel for ordered-set (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8219 sha256=4c2e596e0a0eb7a0c3297c2f8834d635fd1f418f6779034fec85f596b788827b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/fc/ea/ff72bd31a0eccfed87d4c54ab79c94ff95cbbfd773bf676843\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=736983736b06fae5eee97e4dad95705edfa1ce5ec696ecc1a362073e7686d5dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/13/69/7100f11c8ac18af16359fa07f3469ea79bb65d44fdd37db13f\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-py3-none-any.whl size=42723 sha256=4188c011636cf9cc124839cbae526fa17b7195889f8de0e7faf5ed3712f02440\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/e5/aa/06cad987e3e32ab6c816555c9ad66ec1960297c55e325ea008\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893249 sha256=120a965ab3f41f92f1f4e54c7e0961368857e5f867ab8cb7beb7018032752edc\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/2d/8b/438960efb97814d4ea11b22866a99dd68fee8edda2f93a4e1c\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=5796a15fccd3e78636cf5ed5f7da586fcac32148475824ee93a21f39737582db\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/e8/db/ebe4dcd7d7d11208c1e4e4ef246cea4fcc8d463c93405a6555\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=861df9feb3ff3acaa452f0e825bd083ed8a92b6eaa68e3ebede12f478f864456\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/e1/0b/575d02bdf2c7ff9c9be5490db69e8d4e2e26b5523e295137eb\n",
            "Successfully built ftfy future jsonnet nltk ordered-set overrides parsimonious sacremoses wget word2number\n",
            "Installing collected packages: word2number, wget, wasabi, typing-extensions, toml, tokenizers, srsly, snowballstemmer, sentencepiece, pytz, ptyprocess, plac, overrides, murmurhash, jsonnet, iniconfig, filelock, dataclasses, cymem, conllu, certifi, zope.interface, zope.event, zipp, urllib3, Unidecode, traitlets, tqdm, threadpoolctl, sqlparse, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, soupsieve, scipy, python-dateutil, pyparsing, Pygments, py, protobuf, prompt-toolkit, preshed, Pillow, parso, parsimonious, ordered-set, networkx, MarkupSafe, kiwisolver, joblib, jmespath, imagesize, h5py, future, ftfy, flaky, docutils, cycler, blis, Babel, attrs, torch, thinc, tensorboardX, scikit-learn, sacremoses, requests, pandas, packaging, nltk, matplotlib, Jinja2, jedi, importlib-metadata, gevent, botocore, beautifulsoup4, transformers, torchvision, Sphinx, spacy, s3transfer, responses, pluggy, jsonpickle, ipython, Flask, pytest, numpydoc, Flask-Cors, boto3, pytorch-transformers, pytorch-pretrained-bert, allennlp\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 0.10.1\n",
            "    Uninstalling wasabi-0.10.1:\n",
            "      Successfully uninstalled wasabi-0.10.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.1.1\n",
            "    Uninstalling typing_extensions-4.1.1:\n",
            "      Successfully uninstalled typing_extensions-4.1.1\n",
            "  Attempting uninstall: toml\n",
            "    Found existing installation: toml 0.10.2\n",
            "    Uninstalling toml-0.10.2:\n",
            "      Successfully uninstalled toml-0.10.2\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.4\n",
            "    Uninstalling srsly-2.4.4:\n",
            "      Successfully uninstalled srsly-2.4.4\n",
            "  Attempting uninstall: snowballstemmer\n",
            "    Found existing installation: snowballstemmer 2.2.0\n",
            "    Uninstalling snowballstemmer-2.2.0:\n",
            "      Successfully uninstalled snowballstemmer-2.2.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.4\n",
            "    Uninstalling pytz-2022.4:\n",
            "      Successfully uninstalled pytz-2022.4\n",
            "  Attempting uninstall: ptyprocess\n",
            "    Found existing installation: ptyprocess 0.7.0\n",
            "    Uninstalling ptyprocess-0.7.0:\n",
            "      Successfully uninstalled ptyprocess-0.7.0\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.9\n",
            "    Uninstalling murmurhash-1.0.9:\n",
            "      Successfully uninstalled murmurhash-1.0.9\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.7\n",
            "    Uninstalling cymem-2.0.7:\n",
            "      Successfully uninstalled cymem-2.0.7\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.9.0\n",
            "    Uninstalling zipp-3.9.0:\n",
            "      Successfully uninstalled zipp-3.9.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.1.0\n",
            "    Uninstalling threadpoolctl-3.1.0:\n",
            "      Successfully uninstalled threadpoolctl-3.1.0\n",
            "  Attempting uninstall: sqlparse\n",
            "    Found existing installation: sqlparse 0.4.3\n",
            "    Uninstalling sqlparse-0.4.3:\n",
            "      Successfully uninstalled sqlparse-0.4.3\n",
            "  Attempting uninstall: sphinxcontrib-serializinghtml\n",
            "    Found existing installation: sphinxcontrib-serializinghtml 1.1.5\n",
            "    Uninstalling sphinxcontrib-serializinghtml-1.1.5:\n",
            "      Successfully uninstalled sphinxcontrib-serializinghtml-1.1.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: py\n",
            "    Found existing installation: py 1.11.0\n",
            "    Uninstalling py-1.11.0:\n",
            "      Successfully uninstalled py-1.11.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 2.0.10\n",
            "    Uninstalling prompt-toolkit-2.0.10:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.10\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.8\n",
            "    Uninstalling preshed-3.0.8:\n",
            "      Successfully uninstalled preshed-3.0.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.4\n",
            "    Uninstalling kiwisolver-1.4.4:\n",
            "      Successfully uninstalled kiwisolver-1.4.4\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.2.0\n",
            "    Uninstalling joblib-1.2.0:\n",
            "      Successfully uninstalled joblib-1.2.0\n",
            "  Attempting uninstall: imagesize\n",
            "    Found existing installation: imagesize 1.4.1\n",
            "    Uninstalling imagesize-1.4.1:\n",
            "      Successfully uninstalled imagesize-1.4.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.8\n",
            "    Uninstalling blis-0.7.8:\n",
            "      Successfully uninstalled blis-0.7.8\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.10.3\n",
            "    Uninstalling Babel-2.10.3:\n",
            "      Successfully uninstalled Babel-2.10.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 22.1.0\n",
            "    Uninstalling attrs-22.1.0:\n",
            "      Successfully uninstalled attrs-22.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.4\n",
            "    Uninstalling thinc-8.1.4:\n",
            "      Successfully uninstalled thinc-8.1.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.13.0\n",
            "    Uninstalling importlib-metadata-4.13.0:\n",
            "      Successfully uninstalled importlib-metadata-4.13.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: Sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "spacy-loggers 1.0.3 requires wasabi<1.1.0,>=0.8.1, but you have wasabi 0.8.0 which is incompatible.\n",
            "nbformat 5.7.0 requires importlib-metadata>=3.6; python_version < \"3.8\", but you have importlib-metadata 2.0.0 which is incompatible.\n",
            "nbformat 5.7.0 requires traitlets>=5.1, but you have traitlets 5.0.4 which is incompatible.\n",
            "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 2.0.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 2.0.0 which is incompatible.\n",
            "googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.18.1 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.1.9 which is incompatible.\n",
            "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.8.0 Flask-1.1.2 Flask-Cors-3.0.9 Jinja2-2.11.2 MarkupSafe-1.1.1 Pillow-7.2.0 Pygments-2.7.1 Sphinx-3.2.1 Unidecode-1.1.1 allennlp-0.9.0 attrs-20.2.0 beautifulsoup4-4.9.3 blis-0.2.4 boto3-1.15.16 botocore-1.18.16 certifi-2020.6.20 conllu-1.3.1 cycler-0.10.0 cymem-2.0.3 dataclasses-0.6 docutils-0.16 filelock-3.0.12 flaky-3.7.0 ftfy-5.8 future-0.18.2 gevent-20.9.0 h5py-2.10.0 imagesize-1.2.0 importlib-metadata-2.0.0 iniconfig-1.0.1 ipython-7.18.1 jedi-0.17.2 jmespath-0.10.0 joblib-0.17.0 jsonnet-0.16.0 jsonpickle-1.4.1 kiwisolver-1.2.0 matplotlib-3.3.2 murmurhash-1.0.2 networkx-2.5 nltk-3.5 numpydoc-1.1.0 ordered-set-4.0.2 overrides-3.1.0 packaging-20.4 pandas-1.1.3 parsimonious-0.8.1 parso-0.7.1 plac-0.9.6 pluggy-0.13.1 preshed-2.0.1 prompt-toolkit-3.0.8 protobuf-3.13.0 ptyprocess-0.6.0 py-1.9.0 pyparsing-2.4.7 pytest-6.1.1 python-dateutil-2.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 pytz-2020.1 requests-2.24.0 responses-0.12.0 s3transfer-0.3.3 sacremoses-0.0.43 scikit-learn-0.23.2 scipy-1.5.2 sentencepiece-0.1.91 snowballstemmer-2.0.0 soupsieve-2.0.1 spacy-2.1.9 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.4 sqlparse-0.4.1 srsly-1.0.2 tensorboardX-2.1 thinc-7.0.8 threadpoolctl-2.1.0 tokenizers-0.8.1rc2 toml-0.10.1 torch-1.6.0 torchvision-0.7.0 tqdm-4.50.2 traitlets-5.0.4 transformers-3.3.1 typing-extensions-3.7.4.3 urllib3-1.25.10 wasabi-0.8.0 wget-3.2 word2number-1.1 zipp-3.3.0 zope.event-4.5.0 zope.interface-5.1.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCloning into 'zsl-kg'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 127 (delta 7), reused 8 (delta 5), pack-reused 108\u001b[K\n",
            "Receiving objects: 100% (127/127), 34.38 MiB | 16.40 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "/content/nayak-tmlr22-code/zsl-kg\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/nayak-tmlr22-code/zsl-kg\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: allennlp==0.9.0 in /usr/local/lib/python3.7/dist-packages (from zsl-kg==0.0.1) (0.9.0)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from zsl-kg==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (from zsl-kg==0.0.1) (0.7.0)\n",
            "Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.7/dist-packages (from zsl-kg==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: pandas==1.1.3 in /usr/local/lib/python3.7/dist-packages (from zsl-kg==0.0.1) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from zsl-kg==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.8.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.5.3)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (2.1)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.23.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (5.8)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.6.2)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.1.1)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.1)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (6.1.1)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (2020.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.15.16)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.4.1)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (2.1.9)\n",
            "Requirement already satisfied: pytorch-transformers==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (20.9.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (4.50.2)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (2.24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.5.2)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (3.5)\n",
            "Requirement already satisfied: conllu==1.3.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (3.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (2.10.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0->zsl-kg==0.0.1) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.3->zsl-kg==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->zsl-kg==0.0.1) (0.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0->zsl-kg==0.0.1) (7.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (2022.6.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (0.1.91)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0->zsl-kg==0.0.1) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0->zsl-kg==0.0.1) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0->zsl-kg==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.7->allennlp==0.9.0->zsl-kg==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0->zsl-kg==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0->zsl-kg==0.0.1) (4.5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0->zsl-kg==0.0.1) (5.1.2)\n",
            "Requirement already satisfied: greenlet>=0.4.17 in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0->zsl-kg==0.0.1) (1.1.3.post0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0->zsl-kg==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0->zsl-kg==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0->zsl-kg==0.0.1) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0->zsl-kg==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (3.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0->zsl-kg==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0->zsl-kg==0.0.1) (1.25.10)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0->zsl-kg==0.0.1) (2.10)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (7.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (2.0.3)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (0.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0->zsl-kg==0.0.1) (0.9.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==0.9.0->zsl-kg==0.0.1) (3.13.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0->zsl-kg==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0->zsl-kg==0.0.1) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.16 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0->zsl-kg==0.0.1) (1.18.16)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp==0.9.0->zsl-kg==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle->allennlp==0.9.0->zsl-kg==0.0.1) (2.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->allennlp==0.9.0->zsl-kg==0.0.1) (0.17.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0->zsl-kg==0.0.1) (0.10.1)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0->zsl-kg==0.0.1) (0.13.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0->zsl-kg==0.0.1) (20.2.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0->zsl-kg==0.0.1) (20.4)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0->zsl-kg==0.0.1) (1.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==0.9.0->zsl-kg==0.0.1) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle->allennlp==0.9.0->zsl-kg==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp==0.9.0->zsl-kg==0.0.1) (1.1.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (0.7.12)\n",
            "Requirement already satisfied: docutils>=0.12 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (0.16)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.1.4)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.3)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.3)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (2.7.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (2.8.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->zsl-kg==0.0.1) (1.2.0)\n",
            "Building wheels for collected packages: zsl-kg\n",
            "  Building wheel for zsl-kg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zsl-kg: filename=zsl_kg-0.0.1-py3-none-any.whl size=49426 sha256=65ce76f7de77423a464c3b8bbef724f9466da41c538c3faafde63988d6a1fcf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/2f/44/3aba03c0d36dbcd48afd5ffbb8d180a011a7fa300caf85fe16\n",
            "Successfully built zsl-kg\n",
            "Installing collected packages: zsl-kg\n",
            "Successfully installed zsl-kg-0.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/content/nayak-tmlr22-code\n"
          ]
        }
      ],
      "source": [
        "# take care of setting up nayak experiment \n",
        "%cd nayak-tmlr22-code/\n",
        "# delete the last line of requirement file cus it dont work we will do it manually\n",
        "! sed -i '$d' zsl-kg-requirements.txt\n",
        "! pip install --upgrade pip \n",
        "# somehow numpy 1.22 doesnt exist for google colab so we run with 1.21 \n",
        "! sed -i 's/numpy==1.22.0/numpy==1.21.6/g' zsl-kg-requirements.txt\n",
        "! pip install -r zsl-kg-requirements.txt\n",
        "! git clone https://github.com/BatsResearch/zsl-kg.git\n",
        "%cd zsl-kg/\n",
        "! pip install . \n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxQA_G-9y8pu"
      },
      "source": [
        "# Intent Classification Set up\n",
        "\n",
        "1. cd into intent classification \n",
        "2. create folders for data\n",
        "3. download snips subgraph\n",
        "4. download glove dataset \n",
        "5. run main experiments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mU_B-8PyuVa",
        "outputId": "b9732101-2705-4940-8e68-fd09843836d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nayak-tmlr22-code/intent_classification\n"
          ]
        }
      ],
      "source": [
        "# set up intent classification \n",
        "%cd intent_classification/\n",
        "! mkdir data\n",
        "! mkdir data/subgraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSoDZZkEuX-5",
        "outputId": "0b0ba1c2-6a95-4d81-e980-7af7c7843335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1id767oIDz0pZyd7OG5GbGTbOHlJia6cG\n",
            "To: /content/nayak-tmlr22-code/intent_classification/snips_graph.zip\n",
            "100% 18.0M/18.0M [00:00<00:00, 53.8MB/s]\n",
            "Archive:  data/subgraphs/snips_graph.zip\n",
            "   creating: data/subgraphs/snips_graph/\n",
            "   creating: data/subgraphs/snips_graph/train_graph/\n",
            "   creating: data/subgraphs/snips_graph/test_graph/\n",
            "   creating: data/subgraphs/snips_graph/dev_graph/\n",
            "  inflating: data/subgraphs/snips_graph/train_graph/params.pkl  \n",
            "  inflating: data/subgraphs/snips_graph/train_graph/graph_data.pt  \n",
            "  inflating: data/subgraphs/snips_graph/test_graph/params.pkl  \n",
            "  inflating: data/subgraphs/snips_graph/test_graph/graph_data.pt  \n",
            "  inflating: data/subgraphs/snips_graph/dev_graph/params.pkl  \n",
            "  inflating: data/subgraphs/snips_graph/dev_graph/graph_data.pt  \n"
          ]
        }
      ],
      "source": [
        "# download snips subgraph for intent classification \n",
        "# snips subgraph https://drive.google.com/file/d/1id767oIDz0pZyd7OG5GbGTbOHlJia6cG/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1id767oIDz0pZyd7OG5GbGTbOHlJia6cG\n",
        "! mv snips_graph.zip data/subgraphs/snips_graph.zip \n",
        "! unzip -o data/subgraphs/snips_graph.zip -d data/subgraphs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Rw2VtJzpjF",
        "outputId": "c9c45519-4bf9-443f-a371-cca0063cf28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g02oOWf_L4MAxP-NpDKG-cUgfReU9Yfu\n",
            "To: /content/nayak-tmlr22-code/intent_classification/dev.txt\n",
            "100% 203k/203k [00:00<00:00, 105MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QTlLQBynNShu_mNsTikRXsVV4CH73dRr\n",
            "To: /content/nayak-tmlr22-code/intent_classification/test.txt\n",
            "100% 204k/204k [00:00<00:00, 76.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15OW34XpKISmrarzybuirFbqA51qj_2Gm\n",
            "To: /content/nayak-tmlr22-code/intent_classification/train.txt\n",
            "100% 343k/343k [00:00<00:00, 128MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download snips train test validation dataset\n",
        "# dev https://drive.google.com/file/d/1g02oOWf_L4MAxP-NpDKG-cUgfReU9Yfu/view?usp=sharing\n",
        "# test https://drive.google.com/file/d/1QTlLQBynNShu_mNsTikRXsVV4CH73dRr/view?usp=sharing\n",
        "# train https://drive.google.com/file/d/15OW34XpKISmrarzybuirFbqA51qj_2Gm/view?usp=sharing\n",
        "! mkdir data/snips\n",
        "! gdown https://drive.google.com/uc?id=1g02oOWf_L4MAxP-NpDKG-cUgfReU9Yfu\n",
        "! mv dev.txt data/snips/dev.txt\n",
        "! gdown https://drive.google.com/uc?id=1QTlLQBynNShu_mNsTikRXsVV4CH73dRr\n",
        "! mv test.txt data/snips/test.txt\n",
        "! gdown https://drive.google.com/uc?id=15OW34XpKISmrarzybuirFbqA51qj_2Gm\n",
        "! mv train.txt data/snips/train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op_5U9E5Vo_x",
        "outputId": "a338b7a7-0a56-4faf-fe29-f7a9af2dca46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-22 07:19:56--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2022-10-22 07:19:56--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.01MB/s    in 6m 57s  \n",
            "\n",
            "2022-10-22 07:26:54 (4.97 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  data/glove.840B.300d.zip\n",
            "  inflating: data/glove.840B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "# download Glove Data for training \n",
        "! wget https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "! mv glove.840B.300d.zip data/\n",
        "! unzip -o -j data/glove.840B.300d.zip -d data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tphDzQmFk1Pb"
      },
      "source": [
        "## Intent Classification KSL-KG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_dPq0XYfFQo",
        "outputId": "bad51022-be72-4886-f878-5f2a79bcf9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "Training Details\n",
            "DATASET:  snips\n",
            "ENCODER:  trgcn\n",
            "********************\n",
            "5974it [00:00, 30834.28it/s]\n",
            "3914it [00:00, 73713.14it/s]\n",
            "3914it [00:00, 23315.89it/s]\n",
            "100% 13802/13802 [00:00<00:00, 168514.00it/s]\n",
            "Loading GloVe...\n",
            "word embeddings created...\n",
            "Loading the text encoder...\n",
            "Loading the label encoder...\n",
            "**** Epoch 0 ****\n",
            "100% 187/187 [00:06<00:00, 28.88it/s]\n",
            "Train loss = 41.39838282938581\n",
            "100% 123/123 [00:01<00:00, 75.16it/s]\n",
            "Val Loss 113.10227966308594\n",
            "100% 123/123 [00:01<00:00, 88.94it/s]\n",
            "unseen acc =  0.9032\n",
            "**** Epoch 1 ****\n",
            "100% 187/187 [00:06<00:00, 29.34it/s]\n",
            "Train loss = 2.4202372899162583\n",
            "100% 123/123 [00:01<00:00, 77.35it/s]\n",
            "Val Loss 172.45199584960938\n",
            "100% 123/123 [00:01<00:00, 104.38it/s]\n",
            "unseen acc =  0.9198\n",
            "**** Epoch 2 ****\n",
            "100% 187/187 [00:06<00:00, 29.32it/s]\n",
            "Train loss = 1.6195609538990539\n",
            "100% 123/123 [00:01<00:00, 76.26it/s]\n",
            "Val Loss 235.45550537109375\n",
            "100% 123/123 [00:01<00:00, 102.07it/s]\n",
            "unseen acc =  0.9170\n",
            "**** Epoch 3 ****\n",
            "100% 187/187 [00:07<00:00, 24.81it/s]\n",
            "Train loss = 1.0733180479801376\n",
            "100% 123/123 [00:02<00:00, 52.25it/s]\n",
            "Val Loss 310.0397033691406\n",
            "100% 123/123 [00:01<00:00, 65.84it/s]\n",
            "unseen acc =  0.9198\n",
            "**** Epoch 4 ****\n",
            "100% 187/187 [00:07<00:00, 24.92it/s]\n",
            "Train loss = 0.7026408486799482\n",
            "100% 123/123 [00:01<00:00, 77.17it/s]\n",
            "Val Loss 445.97808837890625\n",
            "100% 123/123 [00:01<00:00, 103.93it/s]\n",
            "unseen acc =  0.9223\n",
            "**** Epoch 5 ****\n",
            "100% 187/187 [00:06<00:00, 29.02it/s]\n",
            "Train loss = 0.5888738024414124\n",
            "100% 123/123 [00:01<00:00, 76.12it/s]\n",
            "Val Loss 430.31060791015625\n",
            "100% 123/123 [00:01<00:00, 103.82it/s]\n",
            "unseen acc =  0.8965\n",
            "**** Epoch 6 ****\n",
            "100% 187/187 [00:06<00:00, 29.35it/s]\n",
            "Train loss = 0.5125100077648312\n",
            "100% 123/123 [00:01<00:00, 76.46it/s]\n",
            "Val Loss 485.07891845703125\n",
            "100% 123/123 [00:01<00:00, 102.92it/s]\n",
            "unseen acc =  0.9052\n",
            "**** Epoch 7 ****\n",
            "100% 187/187 [00:06<00:00, 29.37it/s]\n",
            "Train loss = 0.4567196570960732\n",
            "100% 123/123 [00:01<00:00, 77.27it/s]\n",
            "Val Loss 529.1441650390625\n",
            "100% 123/123 [00:01<00:00, 103.12it/s]\n",
            "unseen acc =  0.9021\n",
            "**** Epoch 8 ****\n",
            "100% 187/187 [00:06<00:00, 29.39it/s]\n",
            "Train loss = 0.09897692750473652\n",
            "100% 123/123 [00:01<00:00, 78.25it/s]\n",
            "Val Loss 531.0112915039062\n",
            "100% 123/123 [00:01<00:00, 104.87it/s]\n",
            "unseen acc =  0.8786\n",
            "**** Epoch 9 ****\n",
            "100% 187/187 [00:06<00:00, 29.37it/s]\n",
            "Train loss = 3.62808665819648\n",
            "100% 123/123 [00:01<00:00, 77.93it/s]\n",
            "Val Loss 476.7943115234375\n",
            "100% 123/123 [00:01<00:00, 103.85it/s]\n",
            "unseen acc =  0.5452\n",
            "done with model training\n",
            "loading best model\n",
            "100% 123/123 [00:01<00:00, 102.26it/s]\n",
            "unseen acc =  0.9032\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# --dataset does not work lol there's no option in it\n",
        "# 0.8894, 0.8988 0.8988\n",
        "# 0.9032 trgcn \n",
        "# 2m with GPU LOL trgcn\n",
        "! python train.py --label_encoder_type trgcn --seed 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZryitRuWH1LD"
      },
      "source": [
        "## Intent Classification - Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP-vevEUIXsE",
        "outputId": "b52d8fa4-aedb-45c1-97a6-509595882901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OvAEXJCWULQQl-Go-1Zlz7KUtyLKTHTe\n",
            "To: /content/nayak-tmlr22-code/intent_classification/dense_graph.json\n",
            "100% 520M/520M [00:03<00:00, 149MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY\n",
            "To: /content/nayak-tmlr22-code/intent_classification/induced_graph.json\n",
            "100% 510M/510M [00:03<00:00, 162MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download model for baseline\n",
        "# https://drive.google.com/file/d/1OvAEXJCWULQQl-Go-1Zlz7KUtyLKTHTe/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1OvAEXJCWULQQl-Go-1Zlz7KUtyLKTHTe\n",
        "! mv dense_graph.json data/dense_graph.json\n",
        "# 1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY https://drive.google.com/file/d/1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY\n",
        "! mv induced_graph.json data/induced_graph.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUix8H8mHraF",
        "outputId": "f44364b3-2437-4a12-86df-7dbd221ff4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "Training Details\n",
            "DATASET:  snips\n",
            "ENCODER:  sgcn\n",
            "********************\n",
            "5974it [00:00, 34584.20it/s]\n",
            "3914it [00:00, 67660.38it/s]\n",
            "3914it [00:00, 23462.44it/s]\n",
            "100% 13802/13802 [00:00<00:00, 177406.78it/s]\n",
            "Loading GloVe...\n",
            "word embeddings created...\n",
            "Loading the text encoder...\n",
            "Loading the label encoder...\n",
            "**** Epoch 0 ****\n",
            "100% 187/187 [00:09<00:00, 20.64it/s]\n",
            "Train loss = 79.63661924749613\n",
            "100% 123/123 [00:02<00:00, 61.21it/s]\n",
            "Val Loss 473.8694152832031\n",
            "100% 123/123 [00:01<00:00, 62.97it/s]\n",
            "unseen acc =  0.5158\n",
            "**** Epoch 1 ****\n",
            "100% 187/187 [00:07<00:00, 26.65it/s]\n",
            "Train loss = 3.114745769649744\n",
            "100% 123/123 [00:01<00:00, 64.53it/s]\n",
            "Val Loss 515.5430908203125\n",
            "100% 123/123 [00:01<00:00, 64.58it/s]\n",
            "unseen acc =  0.4888\n",
            "**** Epoch 2 ****\n",
            "100% 187/187 [00:07<00:00, 26.41it/s]\n",
            "Train loss = 2.533518680749694\n",
            "100% 123/123 [00:01<00:00, 64.70it/s]\n",
            "Val Loss 584.8506469726562\n",
            "100% 123/123 [00:01<00:00, 64.99it/s]\n",
            "unseen acc =  0.5110\n",
            "**** Epoch 3 ****\n",
            "100% 187/187 [00:06<00:00, 26.73it/s]\n",
            "Train loss = 1.339745079880231\n",
            "100% 123/123 [00:01<00:00, 64.30it/s]\n",
            "Val Loss 597.0263061523438\n",
            "100% 123/123 [00:01<00:00, 64.76it/s]\n",
            "unseen acc =  0.5345\n",
            "**** Epoch 4 ****\n",
            "100% 187/187 [00:07<00:00, 26.68it/s]\n",
            "Train loss = 0.9655190187841072\n",
            "100% 123/123 [00:01<00:00, 64.94it/s]\n",
            "Val Loss 602.9483032226562\n",
            "100% 123/123 [00:01<00:00, 64.42it/s]\n",
            "unseen acc =  0.5391\n",
            "**** Epoch 5 ****\n",
            "100% 187/187 [00:07<00:00, 26.58it/s]\n",
            "Train loss = 1.609742625249055\n",
            "100% 123/123 [00:01<00:00, 64.55it/s]\n",
            "Val Loss 609.128662109375\n",
            "100% 123/123 [00:01<00:00, 64.23it/s]\n",
            "unseen acc =  0.5194\n",
            "**** Epoch 6 ****\n",
            "100% 187/187 [00:07<00:00, 26.67it/s]\n",
            "Train loss = 0.5733869792220503\n",
            "100% 123/123 [00:01<00:00, 64.35it/s]\n",
            "Val Loss 624.6571655273438\n",
            "100% 123/123 [00:01<00:00, 64.42it/s]\n",
            "unseen acc =  0.6088\n",
            "**** Epoch 7 ****\n",
            "100% 187/187 [00:07<00:00, 26.60it/s]\n",
            "Train loss = 0.7440027454176743\n",
            "100% 123/123 [00:01<00:00, 64.60it/s]\n",
            "Val Loss 673.9483032226562\n",
            "100% 123/123 [00:01<00:00, 64.38it/s]\n",
            "unseen acc =  0.5028\n",
            "**** Epoch 8 ****\n",
            "100% 187/187 [00:07<00:00, 26.65it/s]\n",
            "Train loss = 0.16474887349249911\n",
            "100% 123/123 [00:01<00:00, 64.51it/s]\n",
            "Val Loss 684.50244140625\n",
            "100% 123/123 [00:01<00:00, 64.15it/s]\n",
            "unseen acc =  0.5309\n",
            "**** Epoch 9 ****\n",
            "100% 187/187 [00:07<00:00, 26.42it/s]\n",
            "Train loss = 0.08504649303358747\n",
            "100% 123/123 [00:01<00:00, 63.90it/s]\n",
            "Val Loss 770.715576171875\n",
            "100% 123/123 [00:01<00:00, 63.93it/s]\n",
            "unseen acc =  0.4939\n",
            "done with model training\n",
            "loading best model\n",
            "100% 123/123 [00:01<00:00, 64.13it/s]\n",
            "unseen acc =  0.5158\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# 0.5158\n",
        "! python train.py --label_encoder_type sgcn --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG3fW3FjILiQ",
        "outputId": "b44298a6-195c-4da2-c740-f140b6ddf6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "Training Details\n",
            "DATASET:  snips\n",
            "ENCODER:  gcnz\n",
            "********************\n",
            "5974it [00:00, 31500.60it/s]\n",
            "3914it [00:00, 63724.96it/s]\n",
            "3914it [00:00, 23758.09it/s]\n",
            "100% 13802/13802 [00:00<00:00, 177877.76it/s]\n",
            "Loading GloVe...\n",
            "word embeddings created...\n",
            "Loading the text encoder...\n",
            "Loading the label encoder...\n",
            "**** Epoch 0 ****\n",
            "100% 187/187 [00:07<00:00, 26.45it/s]\n",
            "Train loss = 77.39491848030593\n",
            "100% 123/123 [00:01<00:00, 63.36it/s]\n",
            "Val Loss 494.9127197265625\n",
            "100% 123/123 [00:01<00:00, 63.95it/s]\n",
            "unseen acc =  0.5031\n",
            "**** Epoch 1 ****\n",
            "100% 187/187 [00:06<00:00, 26.99it/s]\n",
            "Train loss = 2.9548677066341043\n",
            "100% 123/123 [00:01<00:00, 65.11it/s]\n",
            "Val Loss 544.1319580078125\n",
            "100% 123/123 [00:01<00:00, 65.06it/s]\n",
            "unseen acc =  0.4888\n",
            "**** Epoch 2 ****\n",
            "100% 187/187 [00:06<00:00, 26.74it/s]\n",
            "Train loss = 2.402949110895861\n",
            "100% 123/123 [00:01<00:00, 64.85it/s]\n",
            "Val Loss 532.2772216796875\n",
            "100% 123/123 [00:01<00:00, 64.61it/s]\n",
            "unseen acc =  0.5148\n",
            "**** Epoch 3 ****\n",
            "100% 187/187 [00:06<00:00, 26.72it/s]\n",
            "Train loss = 1.5240366799407639\n",
            "100% 123/123 [00:01<00:00, 65.03it/s]\n",
            "Val Loss 537.7257690429688\n",
            "100% 123/123 [00:01<00:00, 65.03it/s]\n",
            "unseen acc =  0.5483\n",
            "**** Epoch 4 ****\n",
            "100% 187/187 [00:06<00:00, 26.73it/s]\n",
            "Train loss = 1.173448238245328\n",
            "100% 123/123 [00:01<00:00, 64.60it/s]\n",
            "Val Loss 567.1273803710938\n",
            "100% 123/123 [00:01<00:00, 64.48it/s]\n",
            "unseen acc =  0.5143\n",
            "**** Epoch 5 ****\n",
            "100% 187/187 [00:07<00:00, 26.54it/s]\n",
            "Train loss = 1.4085370860702824\n",
            "100% 123/123 [00:01<00:00, 64.35it/s]\n",
            "Val Loss 590.748291015625\n",
            "100% 123/123 [00:01<00:00, 64.40it/s]\n",
            "unseen acc =  0.5465\n",
            "**** Epoch 6 ****\n",
            "100% 187/187 [00:07<00:00, 26.67it/s]\n",
            "Train loss = 0.5071247231771849\n",
            "100% 123/123 [00:01<00:00, 64.62it/s]\n",
            "Val Loss 579.1143798828125\n",
            "100% 123/123 [00:01<00:00, 64.36it/s]\n",
            "unseen acc =  0.5263\n",
            "**** Epoch 7 ****\n",
            "100% 187/187 [00:08<00:00, 22.52it/s]\n",
            "Train loss = 0.2821322574304759\n",
            "100% 123/123 [00:02<00:00, 53.10it/s]\n",
            "Val Loss 599.7738647460938\n",
            "100% 123/123 [00:02<00:00, 53.70it/s]\n",
            "unseen acc =  0.5631\n",
            "**** Epoch 8 ****\n",
            "100% 187/187 [00:06<00:00, 26.75it/s]\n",
            "Train loss = 0.16404249884135425\n",
            "100% 123/123 [00:01<00:00, 63.95it/s]\n",
            "Val Loss 647.6526489257812\n",
            "100% 123/123 [00:01<00:00, 64.18it/s]\n",
            "unseen acc =  0.5345\n",
            "**** Epoch 9 ****\n",
            "100% 187/187 [00:07<00:00, 26.60it/s]\n",
            "Train loss = 0.09696002802729708\n",
            "100% 123/123 [00:01<00:00, 64.11it/s]\n",
            "Val Loss 736.6085205078125\n",
            "100% 123/123 [00:01<00:00, 64.01it/s]\n",
            "unseen acc =  0.4898\n",
            "done with model training\n",
            "loading best model\n",
            "100% 123/123 [00:01<00:00, 64.11it/s]\n",
            "unseen acc =  0.5031\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# 0.5031\n",
        "! python train.py --label_encoder_type gcnz --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paI7H-sMIObq",
        "outputId": "cfebf807-e28e-4824-870d-50b3bf12170e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "Training Details\n",
            "DATASET:  snips\n",
            "ENCODER:  dgp\n",
            "********************\n",
            "5974it [00:00, 32703.08it/s]\n",
            "3914it [00:00, 73336.10it/s]\n",
            "3914it [00:00, 23413.65it/s]\n",
            "100% 13802/13802 [00:00<00:00, 165718.03it/s]\n",
            "Loading GloVe...\n",
            "word embeddings created...\n",
            "Loading the text encoder...\n",
            "Loading the label encoder...\n",
            "edges_set [82115, 75850, 78502, 81000, 83954, 84148, 78505, 65764, 45318, 29248, 18202, 10419, 5829, 3239, 1821, 972, 524, 183, 30]\n",
            "edges_set [82115, 75850, 78502, 81000, 428156]\n",
            "/content/nayak-tmlr22-code/intent_classification/utils/common.py:80: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n",
            "**** Epoch 0 ****\n",
            "100% 187/187 [00:37<00:00,  5.01it/s]\n",
            "Train loss = 95.44765615835786\n",
            "100% 123/123 [00:11<00:00, 10.69it/s]\n",
            "Val Loss 299.0398864746094\n",
            "100% 123/123 [00:11<00:00, 10.65it/s]\n",
            "unseen acc =  0.6773\n",
            "**** Epoch 1 ****\n",
            "100% 187/187 [00:38<00:00,  4.88it/s]\n",
            "Train loss = 3.3909671509172767\n",
            "100% 123/123 [00:11<00:00, 10.67it/s]\n",
            "Val Loss 354.9403381347656\n",
            "100% 123/123 [00:11<00:00, 10.67it/s]\n",
            "unseen acc =  0.6962\n",
            "**** Epoch 2 ****\n",
            "100% 187/187 [00:37<00:00,  5.00it/s]\n",
            "Train loss = 2.6739630850206595\n",
            "100% 123/123 [00:11<00:00, 10.72it/s]\n",
            "Val Loss 392.2981262207031\n",
            "100% 123/123 [00:11<00:00, 10.71it/s]\n",
            "unseen acc =  0.6083\n",
            "**** Epoch 3 ****\n",
            "100% 187/187 [00:37<00:00,  4.93it/s]\n",
            "Train loss = 1.4664625433288165\n",
            "100% 123/123 [00:11<00:00, 10.71it/s]\n",
            "Val Loss 431.90484619140625\n",
            "100% 123/123 [00:11<00:00, 10.69it/s]\n",
            "unseen acc =  0.6150\n",
            "**** Epoch 4 ****\n",
            "100% 187/187 [00:37<00:00,  5.01it/s]\n",
            "Train loss = 0.7914713084792311\n",
            "100% 123/123 [00:11<00:00, 10.72it/s]\n",
            "Val Loss 527.58447265625\n",
            "100% 123/123 [00:11<00:00, 10.73it/s]\n",
            "unseen acc =  0.5327\n",
            "**** Epoch 5 ****\n",
            "100% 187/187 [00:37<00:00,  5.00it/s]\n",
            "Train loss = 0.9716073048111866\n",
            "100% 123/123 [00:11<00:00, 10.59it/s]\n",
            "Val Loss 488.84149169921875\n",
            "100% 123/123 [00:11<00:00, 10.75it/s]\n",
            "unseen acc =  0.6702\n",
            "**** Epoch 6 ****\n",
            "100% 187/187 [00:36<00:00,  5.06it/s]\n",
            "Train loss = 0.7615577757678693\n",
            "100% 123/123 [00:11<00:00, 10.75it/s]\n",
            "Val Loss 478.9098815917969\n",
            "100% 123/123 [00:11<00:00, 10.70it/s]\n",
            "unseen acc =  0.6638\n",
            "**** Epoch 7 ****\n",
            "100% 187/187 [00:37<00:00,  5.00it/s]\n",
            "Train loss = 0.29846109405389143\n",
            "100% 123/123 [00:11<00:00, 10.50it/s]\n",
            "Val Loss 490.414794921875\n",
            "100% 123/123 [00:11<00:00, 10.38it/s]\n",
            "unseen acc =  0.7138\n",
            "**** Epoch 8 ****\n",
            "100% 187/187 [00:37<00:00,  5.00it/s]\n",
            "Train loss = 0.6082559817277797\n",
            "100% 123/123 [00:11<00:00, 10.64it/s]\n",
            "Val Loss 505.8227233886719\n",
            "100% 123/123 [00:11<00:00, 10.67it/s]\n",
            "unseen acc =  0.7144\n",
            "**** Epoch 9 ****\n",
            "100% 187/187 [00:37<00:00,  5.02it/s]\n",
            "Train loss = 0.723022791128642\n",
            "100% 123/123 [00:11<00:00, 10.67it/s]\n",
            "Val Loss 614.0567626953125\n",
            "100% 123/123 [00:11<00:00, 10.44it/s]\n",
            "unseen acc =  0.5636\n",
            "done with model training\n",
            "loading best model\n",
            "100% 123/123 [00:11<00:00, 10.42it/s]\n",
            "unseen acc =  0.6773\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# 0.7420\n",
        "! python train.py --label_encoder_type dgp --seed 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2wFQKp1NA0X"
      },
      "source": [
        "# Fine Grain Entity Typing Experiments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoPbuXMCfPXd"
      },
      "outputs": [],
      "source": [
        "# come out from intent classi if needed\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OecdAYhDNF42",
        "outputId": "97fcd517-f56f-43be-d48c-d8b4fb2be019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nayak-tmlr22-code/fget\n"
          ]
        }
      ],
      "source": [
        "# make datset folder for ontonotes and bbn\n",
        "\n",
        "%cd fget\n",
        "! mkdir data\n",
        "! mkdir data/ontonotes\n",
        "! mkdir data/bbn\n",
        "! mkdir data/subgraphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqfCfedqNF7L",
        "outputId": "48411736-d169-4591-e613-98f4b7d1a6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1NvFec7YiCPiNuRR-C70zvbezEKBXtdHn clean_test.json\n",
            "Processing file 1AbMsVh-MuOK_4pVPeiHmGq9O1II8Ipzo clean_train.json\n",
            "Processing file 1ncNy1u-1_WHdWT16kFm3jb_lD5tPYHos test_labels.csv\n",
            "Processing file 1lwwyGEQdwmaiPYFJz2deyo4l0edvxLJJ test.json\n",
            "Processing file 12afemqJ5UfXS7HigirQ33vbq6mQdi5d3 train_labels.csv\n",
            "Processing file 17RELsEbtjf037HyiwXqwY1ghjTREnnjq train.json\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NvFec7YiCPiNuRR-C70zvbezEKBXtdHn\n",
            "To: /content/nayak-tmlr22-code/fget/data/bbn/clean_test.json\n",
            "100% 4.60M/4.60M [00:00<00:00, 185MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AbMsVh-MuOK_4pVPeiHmGq9O1II8Ipzo\n",
            "To: /content/nayak-tmlr22-code/fget/data/bbn/clean_train.json\n",
            "100% 29.3M/29.3M [00:00<00:00, 188MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ncNy1u-1_WHdWT16kFm3jb_lD5tPYHos\n",
            "To: /content/nayak-tmlr22-code/fget/data/bbn/test_labels.csv\n",
            "100% 526/526 [00:00<00:00, 1.37MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lwwyGEQdwmaiPYFJz2deyo4l0edvxLJJ\n",
            "To: /content/nayak-tmlr22-code/fget/data/bbn/test.json\n",
            "100% 2.68M/2.68M [00:00<00:00, 188MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12afemqJ5UfXS7HigirQ33vbq6mQdi5d3\n",
            "To: /content/nayak-tmlr22-code/fget/data/bbn/train_labels.csv\n",
            "100% 179/179 [00:00<00:00, 571kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17RELsEbtjf037HyiwXqwY1ghjTREnnjq\n",
            "To: /content/nayak-tmlr22-code/fget/data/bbn/train.json\n",
            "100% 14.7M/14.7M [00:00<00:00, 204MB/s]\n",
            "Download completed\n",
            "Retrieving folder list\n",
            "Processing file 1AVvRT2GgNplciOt4PfENEEpCAHh5qfYH clean_test.json\n",
            "Processing file 1OxLJunjZJGaq6nzLoEg3UYvh4uuO2WgO clean_train.json\n",
            "Processing file 1DPw5cUQNOi7h9RNzEByRJU0-0upT4eV8 test_labels.csv\n",
            "Processing file 1_t43hVCIYP9DY-v54q8eBSC87YZzYUEW test.json\n",
            "Processing file 17dGqbHGDfEzUcXNTLzPuMiQCFiWVC5rz train_labels.csv\n",
            "Processing file 1SALP-zQ8aG58F3gGPeprYRPivyjgvml- train.json\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AVvRT2GgNplciOt4PfENEEpCAHh5qfYH\n",
            "To: /content/nayak-tmlr22-code/fget/data/ontonotes/clean_test.json\n",
            "100% 3.96M/3.96M [00:00<00:00, 248MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OxLJunjZJGaq6nzLoEg3UYvh4uuO2WgO\n",
            "To: /content/nayak-tmlr22-code/fget/data/ontonotes/clean_train.json\n",
            "100% 76.2M/76.2M [00:00<00:00, 176MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPw5cUQNOi7h9RNzEByRJU0-0upT4eV8\n",
            "To: /content/nayak-tmlr22-code/fget/data/ontonotes/test_labels.csv\n",
            "100% 878/878 [00:00<00:00, 2.48MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_t43hVCIYP9DY-v54q8eBSC87YZzYUEW\n",
            "To: /content/nayak-tmlr22-code/fget/data/ontonotes/test.json\n",
            "100% 977k/977k [00:00<00:00, 137MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17dGqbHGDfEzUcXNTLzPuMiQCFiWVC5rz\n",
            "To: /content/nayak-tmlr22-code/fget/data/ontonotes/train_labels.csv\n",
            "100% 820/820 [00:00<00:00, 2.35MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SALP-zQ8aG58F3gGPeprYRPivyjgvml-\n",
            "To: /content/nayak-tmlr22-code/fget/data/ontonotes/train.json\n",
            "100% 40.8M/40.8M [00:00<00:00, 215MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "# https://drive.google.com/drive/folders/1GSIcHfNN9fWpg0R7e0qFLMO8MJllDePT?usp=sharing\n",
        "! gdown https://drive.google.com/drive/folders/1GSIcHfNN9fWpg0R7e0qFLMO8MJllDePT -O data/bbn --folder\n",
        "# ! mv data/bbn/* data/\n",
        "# https://drive.google.com/drive/folders/19DgAE1VyjQhqO-EocAIvUvrhq_lzdbBs?usp=sharing\n",
        "! gdown https://drive.google.com/drive/folders/19DgAE1VyjQhqO-EocAIvUvrhq_lzdbBs -O data/ontonotes --folder\n",
        "# ! mv data/ontonotes/* data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUsRzbF3NF9w",
        "outputId": "1fd849cf-2cd5-4a9b-97ef-60b84da580de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OvAEXJCWULQQl-Go-1Zlz7KUtyLKTHTe\n",
            "To: /content/nayak-tmlr22-code/fget/dense_graph.json\n",
            "100% 520M/520M [00:05<00:00, 91.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY\n",
            "To: /content/nayak-tmlr22-code/fget/induced_graph.json\n",
            "100% 510M/510M [00:06<00:00, 80.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download model for baseline\n",
        "# https://drive.google.com/file/d/1OvAEXJCWULQQl-Go-1Zlz7KUtyLKTHTe/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1OvAEXJCWULQQl-Go-1Zlz7KUtyLKTHTe\n",
        "! mv dense_graph.json data/dense_graph.json\n",
        "# 1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY https://drive.google.com/file/d/1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1ixbUf7wC2xQVx4WnSUnhsriUBNTn1EsY\n",
        "! mv induced_graph.json data/induced_graph.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpSZ1jUNGA4",
        "outputId": "d8db79e4-fc77-4588-af9c-0017a649b16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14_y0nPZHrNqxdRLJsmyp48S35uqv_zEZ\n",
            "To: /content/nayak-tmlr22-code/fget/ontonotes_graph.zip\n",
            "100% 890M/890M [00:16<00:00, 55.3MB/s]\n",
            "Archive:  data/subgraphs/ontonotes_graph.zip\n",
            "   creating: data/subgraphs/ontonotes_graph/\n",
            "   creating: data/subgraphs/ontonotes_graph/train_graph/\n",
            "   creating: data/subgraphs/ontonotes_graph/test_graph/\n",
            "  inflating: data/subgraphs/ontonotes_graph/train_graph/params.pkl  \n",
            "  inflating: data/subgraphs/ontonotes_graph/train_graph/graph_data.pt  \n",
            "  inflating: data/subgraphs/ontonotes_graph/test_graph/params.pkl  \n",
            "  inflating: data/subgraphs/ontonotes_graph/test_graph/graph_data.pt  \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jQ68xyliodv3DfTWmo12uk83NU4qkU6w\n",
            "To: /content/nayak-tmlr22-code/fget/bbn_graph.zip\n",
            "100% 839M/839M [00:14<00:00, 56.9MB/s]\n",
            "Archive:  data/subgraphs/bbn_graph.zip\n",
            "   creating: data/subgraphs/bbn_graph/\n",
            "  inflating: data/subgraphs/bbn_graph/.DS_Store  \n",
            "  inflating: data/subgraphs/__MACOSX/bbn_graph/._.DS_Store  \n",
            "   creating: data/subgraphs/bbn_graph/train_graph/\n",
            "   creating: data/subgraphs/bbn_graph/test_graph/\n",
            "  inflating: data/subgraphs/bbn_graph/train_graph/params.pkl  \n",
            "  inflating: data/subgraphs/bbn_graph/train_graph/graph_data.pt  \n",
            "  inflating: data/subgraphs/bbn_graph/test_graph/params.pkl  \n",
            "  inflating: data/subgraphs/bbn_graph/test_graph/graph_data.pt  \n"
          ]
        }
      ],
      "source": [
        "# onto https://drive.google.com/file/d/14_y0nPZHrNqxdRLJsmyp48S35uqv_zEZ/view?usp=sharing\n",
        "# bbn https://drive.google.com/file/d/1jQ68xyliodv3DfTWmo12uk83NU4qkU6w/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=14_y0nPZHrNqxdRLJsmyp48S35uqv_zEZ\n",
        "! mv ontonotes_graph.zip data/subgraphs/ontonotes_graph.zip\n",
        "! unzip -o data/subgraphs/ontonotes_graph.zip -d data/subgraphs/\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=1jQ68xyliodv3DfTWmo12uk83NU4qkU6w\n",
        "! mv bbn_graph.zip data/subgraphs/bbn_graph.zip\n",
        "! unzip -o data/subgraphs/bbn_graph.zip -d data/subgraphs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEm7AWiXbwfd",
        "outputId": "776692ac-3dda-4949-ba4a-ad91afc78a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-22 09:14:19--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2022-10-22 09:14:20--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  4.98MB/s    in 6m 50s  \n",
            "\n",
            "2022-10-22 09:21:11 (5.07 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  data/glove.840B.300d.zip\n",
            "  inflating: data/glove.840B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "# download Glove Data for training \n",
        "! wget https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "! mv glove.840B.300d.zip data/\n",
        "! unzip -o -j data/glove.840B.300d.zip -d data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ridpQky6cZo1"
      },
      "source": [
        "## FGET BBN dataset\n",
        "\n",
        "first we do main run (lstm encoder just like the paper use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQLZ-nR6NGCe",
        "outputId": "ed456b24-a9fa-4a39-fb37-324a6196bd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85545it [00:05, 14827.95it/s]\n",
            "12349it [00:01, 10685.05it/s]\n",
            "2196017it [00:46, 46971.96it/s]\n",
            "dataset: bbn\n",
            "label encoder: trgcn\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 86/86 [00:26<00:00,  3.26it/s]\n",
            "train loss 26.8124\n",
            "100% 13/13 [00:04<00:00,  3.21it/s]\n",
            "OVERALL: strict=0.2318, loose micro=0.1741, loose macro=0.2322\n",
            "SEEN: strict=0.2318, loose micro=0.2323, loose macro=0.2323\n",
            "UNSEEN: strict=0.5250, loose micro=0.5250, loose macro=0.5250\n",
            "--epoch 2--\n",
            "100% 86/86 [00:20<00:00,  4.10it/s]\n",
            "train loss 17.8985\n",
            "100% 13/13 [00:03<00:00,  3.48it/s]\n",
            "OVERALL: strict=0.2302, loose micro=0.1956, loose macro=0.2494\n",
            "SEEN: strict=0.3672, loose micro=0.3870, loose macro=0.3856\n",
            "UNSEEN: strict=0.0067, loose micro=0.0070, loose macro=0.0069\n",
            "--epoch 3--\n",
            "100% 86/86 [00:21<00:00,  4.09it/s]\n",
            "train loss 15.1423\n",
            "100% 13/13 [00:03<00:00,  3.49it/s]\n",
            "OVERALL: strict=0.2348, loose micro=0.3902, loose macro=0.4697\n",
            "SEEN: strict=0.4608, loose micro=0.5947, loose macro=0.6052\n",
            "UNSEEN: strict=0.2369, loose micro=0.2025, loose macro=0.2429\n",
            "--epoch 4--\n",
            "100% 86/86 [00:21<00:00,  4.05it/s]\n",
            "train loss 13.6003\n",
            "100% 13/13 [00:03<00:00,  3.43it/s]\n",
            "OVERALL: strict=0.2355, loose micro=0.4704, loose macro=0.5561\n",
            "SEEN: strict=0.5899, loose micro=0.7129, loose macro=0.7322\n",
            "UNSEEN: strict=0.2330, loose micro=0.2052, loose macro=0.2386\n",
            "--epoch 5--\n",
            "100% 86/86 [00:21<00:00,  4.04it/s]\n",
            "train loss 12.4948\n",
            "100% 13/13 [00:03<00:00,  3.41it/s]\n",
            "OVERALL: strict=0.3097, loose micro=0.5072, loose macro=0.6274\n",
            "SEEN: strict=0.6252, loose micro=0.7386, loose macro=0.7608\n",
            "UNSEEN: strict=0.4274, loose micro=0.3846, loose macro=0.5081\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "OVERALL: strict=0.0189, loose micro=0.3185, loose macro=0.3826\n",
        "SEEN: strict=0.3507, loose micro=0.5569, loose macro=0.5594\n",
        "UNSEEN: strict=0.0483, loose micro=0.1567, loose macro=0.1592\n",
        "\n",
        "OVERALL: strict=0.2531, loose micro=0.4327, loose macro=0.5354\n",
        "SEEN: strict=0.4932, loose micro=0.6235, loose macro=0.6380\n",
        "UNSEEN: strict=0.5007, loose micro=0.4445, loose macro=0.5996\n",
        "--epoch 5--\n",
        "100% 86/86 [07:34<00:00,  5.29s/it]\n",
        "train loss 13.0946\n",
        "100% 13/13 [00:52<00:00,  4.02s/it]\n",
        "OVERALL: strict=0.3097, loose micro=0.5072, loose macro=0.6274\n",
        "SEEN: strict=0.6252, loose micro=0.7386, loose macro=0.7608\n",
        "UNSEEN: strict=0.4274, loose micro=0.3846, loose macro=0.5081\n",
        "\"\"\"\n",
        "# main run \n",
        "! python train.py --dataset bbn --label_encoder_type trgcn --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-40JpoVcisb",
        "outputId": "3ca78cd0-fa03-4c22-a6ce-12f41439199a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85545it [00:05, 14843.29it/s]\n",
            "12349it [00:01, 10616.93it/s]\n",
            "2196017it [00:47, 45899.24it/s]\n",
            "dataset: bbn\n",
            "label encoder: sgcn\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 86/86 [00:15<00:00,  5.38it/s]\n",
            "train loss 24.3528\n",
            "100% 13/13 [00:01<00:00,  8.50it/s]\n",
            "OVERALL: strict=0.2237, loose micro=0.2275, loose macro=0.2694\n",
            "SEEN: strict=0.4418, loose micro=0.4561, loose macro=0.4559\n",
            "UNSEEN: strict=0.0111, loose micro=0.0438, loose macro=0.0289\n",
            "--epoch 2--\n",
            "100% 86/86 [00:16<00:00,  5.18it/s]\n",
            "train loss 14.8348\n",
            "100% 13/13 [00:01<00:00, 11.40it/s]\n",
            "OVERALL: strict=0.2386, loose micro=0.4141, loose macro=0.4894\n",
            "SEEN: strict=0.4701, loose micro=0.5983, loose macro=0.6062\n",
            "UNSEEN: strict=0.0195, loose micro=0.1457, loose macro=0.1075\n",
            "--epoch 3--\n",
            "100% 86/86 [00:12<00:00,  7.03it/s]\n",
            "train loss 13.0617\n",
            "100% 13/13 [00:01<00:00, 11.58it/s]\n",
            "OVERALL: strict=0.2416, loose micro=0.4878, loose macro=0.5951\n",
            "SEEN: strict=0.6103, loose micro=0.7297, loose macro=0.7523\n",
            "UNSEEN: strict=0.0552, loose micro=0.2440, loose macro=0.2206\n",
            "--epoch 4--\n",
            "100% 86/86 [00:13<00:00,  6.51it/s]\n",
            "train loss 11.9897\n",
            "100% 13/13 [00:01<00:00, 11.70it/s]\n",
            "OVERALL: strict=0.2463, loose micro=0.5033, loose macro=0.5925\n",
            "SEEN: strict=0.6111, loose micro=0.7296, loose macro=0.7501\n",
            "UNSEEN: strict=0.0724, loose micro=0.2618, loose macro=0.2456\n",
            "--epoch 5--\n",
            "100% 86/86 [00:12<00:00,  7.12it/s]\n",
            "train loss 11.4531\n",
            "100% 13/13 [00:01<00:00, 11.47it/s]\n",
            "OVERALL: strict=0.2505, loose micro=0.5068, loose macro=0.6022\n",
            "SEEN: strict=0.6200, loose micro=0.7345, loose macro=0.7570\n",
            "UNSEEN: strict=0.1216, loose micro=0.3019, loose macro=0.3156\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "OVERALL: strict=0.2505, loose micro=0.5068, loose macro=0.6022\n",
        "SEEN: strict=0.6200, loose micro=0.7345, loose macro=0.7570\n",
        "UNSEEN: strict=0.1216, loose micro=0.3019, loose macro=0.3156\n",
        "\"\"\"\n",
        "! python train.py --dataset bbn --label_encoder_type sgcn --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-jP2RUHciyc",
        "outputId": "a076c86c-a817-4b82-835d-cdb93242afd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85545it [00:05, 15285.65it/s]\n",
            "12349it [00:01, 10838.36it/s]\n",
            "2196017it [00:45, 48649.23it/s]\n",
            "dataset: bbn\n",
            "label encoder: gcnz\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 86/86 [00:16<00:00,  5.37it/s]\n",
            "train loss 25.1161\n",
            "100% 13/13 [00:01<00:00,  9.03it/s]\n",
            "OVERALL: strict=0.2314, loose micro=0.2127, loose macro=0.2700\n",
            "SEEN: strict=0.2826, loose micro=0.2840, loose macro=0.2838\n",
            "UNSEEN: strict=0.0156, loose micro=0.0157, loose macro=0.0157\n",
            "--epoch 2--\n",
            "100% 86/86 [00:13<00:00,  6.44it/s]\n",
            "train loss 15.2619\n",
            "100% 13/13 [00:01<00:00, 11.51it/s]\n",
            "OVERALL: strict=0.2361, loose micro=0.3670, loose macro=0.4585\n",
            "SEEN: strict=0.4154, loose micro=0.5596, loose macro=0.5636\n",
            "UNSEEN: strict=0.0222, loose micro=0.1097, loose macro=0.0728\n",
            "--epoch 3--\n",
            "100% 86/86 [00:12<00:00,  7.03it/s]\n",
            "train loss 13.1528\n",
            "100% 13/13 [00:01<00:00, 11.20it/s]\n",
            "OVERALL: strict=0.2373, loose micro=0.4289, loose macro=0.5382\n",
            "SEEN: strict=0.5730, loose micro=0.7100, loose macro=0.7323\n",
            "UNSEEN: strict=0.0283, loose micro=0.1588, loose macro=0.1274\n",
            "--epoch 4--\n",
            "100% 86/86 [00:13<00:00,  6.47it/s]\n",
            "train loss 12.1508\n",
            "100% 13/13 [00:01<00:00, 11.39it/s]\n",
            "OVERALL: strict=0.2322, loose micro=0.4685, loose macro=0.5628\n",
            "SEEN: strict=0.5891, loose micro=0.7164, loose macro=0.7375\n",
            "UNSEEN: strict=0.0264, loose micro=0.1826, loose macro=0.1495\n",
            "--epoch 5--\n",
            "100% 86/86 [00:12<00:00,  7.09it/s]\n",
            "train loss 11.5025\n",
            "100% 13/13 [00:01<00:00, 11.72it/s]\n",
            "OVERALL: strict=0.2352, loose micro=0.4629, loose macro=0.5719\n",
            "SEEN: strict=0.5859, loose micro=0.7197, loose macro=0.7434\n",
            "UNSEEN: strict=0.0319, loose micro=0.2066, loose macro=0.1841\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "OVERALL: strict=0.2352, loose micro=0.4629, loose macro=0.5719\n",
        "SEEN: strict=0.5859, loose micro=0.7197, loose macro=0.7434\n",
        "UNSEEN: strict=0.0319, loose micro=0.2066, loose macro=0.1841\n",
        "\"\"\"\n",
        "! python train.py --dataset bbn --label_encoder_type gcnz --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZVdGmEvcXkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752d9bc0-8703-46e9-a741-3e811537cac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85545it [00:05, 15281.40it/s]\n",
            "12349it [00:01, 10903.99it/s]\n",
            "2196017it [00:48, 45617.04it/s]\n",
            "edges_set [82115, 75850, 78502, 81000, 83954, 84148, 78505, 65764, 45318, 29248, 18202, 10419, 5829, 3239, 1821, 972, 524, 183, 30]\n",
            "edges_set [82115, 75850, 78502, 81000, 428156]\n",
            "/content/nayak-tmlr22-code/fget/utils/common.py:165: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n",
            "dataset: bbn\n",
            "label encoder: dgp\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 86/86 [00:42<00:00,  2.04it/s]\n",
            "train loss 26.7081\n",
            "100% 13/13 [00:04<00:00,  2.86it/s]\n",
            "OVERALL: strict=0.0246, loose micro=0.3378, loose macro=0.3112\n",
            "SEEN: strict=0.4506, loose micro=0.4507, loose macro=0.4507\n",
            "UNSEEN: strict=0.0090, loose micro=0.0090, loose macro=0.0090\n",
            "--epoch 2--\n",
            "100% 86/86 [00:39<00:00,  2.17it/s]\n",
            "train loss 16.9567\n",
            "100% 13/13 [00:03<00:00,  3.69it/s]\n",
            "OVERALL: strict=0.2258, loose micro=0.3243, loose macro=0.3745\n",
            "SEEN: strict=0.3362, loose micro=0.4919, loose macro=0.4887\n",
            "UNSEEN: strict=0.0096, loose micro=0.1415, loose macro=0.0799\n",
            "--epoch 3--\n",
            "100% 86/86 [00:40<00:00,  2.13it/s]\n",
            "train loss 14.0136\n",
            "100% 13/13 [00:04<00:00,  3.01it/s]\n",
            "OVERALL: strict=0.2268, loose micro=0.4265, loose macro=0.5163\n",
            "SEEN: strict=0.5526, loose micro=0.6787, loose macro=0.6944\n",
            "UNSEEN: strict=0.0097, loose micro=0.1545, loose macro=0.0990\n",
            "--epoch 4--\n",
            "100% 86/86 [00:39<00:00,  2.17it/s]\n",
            "train loss 12.8665\n",
            "100% 13/13 [00:03<00:00,  4.11it/s]\n",
            "OVERALL: strict=0.2350, loose micro=0.4619, loose macro=0.5827\n",
            "SEEN: strict=0.6140, loose micro=0.7330, loose macro=0.7554\n",
            "UNSEEN: strict=0.0148, loose micro=0.1573, loose macro=0.1082\n",
            "--epoch 5--\n",
            "100% 86/86 [00:39<00:00,  2.18it/s]\n",
            "train loss 12.1778\n",
            "100% 13/13 [00:03<00:00,  4.09it/s]\n",
            "OVERALL: strict=0.2447, loose micro=0.4736, loose macro=0.5955\n",
            "SEEN: strict=0.6236, loose micro=0.7375, loose macro=0.7594\n",
            "UNSEEN: strict=0.0234, loose micro=0.1719, loose macro=0.1262\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "OVERALL: strict=0.2447, loose micro=0.4736, loose macro=0.5955\n",
        "SEEN: strict=0.6236, loose micro=0.7375, loose macro=0.7594\n",
        "UNSEEN: strict=0.0234, loose micro=0.1719, loose macro=0.1262\n",
        "\"\"\"\n",
        "! python train.py --dataset bbn --label_encoder_type dgp --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YlovH12NGFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677c7159-ee5d-4fd7-b87a-79228a265c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85545it [00:07, 11911.13it/s]\n",
            "12349it [00:01, 10601.94it/s]\n",
            "2196017it [00:44, 49273.81it/s]\n",
            "2196017it [00:32, 68194.29it/s]\n",
            "dataset: bbn\n",
            "label encoder: otyper\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 86/86 [00:12<00:00,  7.10it/s]\n",
            "train loss 19.1072\n",
            "100% 13/13 [00:02<00:00,  5.35it/s]\n",
            "OVERALL: strict=0.2517, loose micro=0.5214, loose macro=0.5911\n",
            "SEEN: strict=0.6093, loose micro=0.7123, loose macro=0.7294\n",
            "UNSEEN: strict=0.0738, loose micro=0.1152, loose macro=0.1045\n",
            "--epoch 2--\n",
            "100% 86/86 [00:09<00:00,  9.25it/s]\n",
            "train loss 11.9103\n",
            "100% 13/13 [00:01<00:00, 12.38it/s]\n",
            "OVERALL: strict=0.2520, loose micro=0.5307, loose macro=0.6000\n",
            "SEEN: strict=0.6179, loose micro=0.7238, loose macro=0.7419\n",
            "UNSEEN: strict=0.1346, loose micro=0.1853, loose macro=0.1816\n",
            "--epoch 3--\n",
            "100% 86/86 [00:10<00:00,  8.25it/s]\n",
            "train loss 10.8423\n",
            "100% 13/13 [00:01<00:00, 12.54it/s]\n",
            "OVERALL: strict=0.2587, loose micro=0.5367, loose macro=0.6283\n",
            "SEEN: strict=0.6481, loose micro=0.7556, loose macro=0.7788\n",
            "UNSEEN: strict=0.1864, loose micro=0.2532, loose macro=0.2665\n",
            "--epoch 4--\n",
            "100% 86/86 [00:12<00:00,  6.62it/s]\n",
            "train loss 10.2786\n",
            "100% 13/13 [00:00<00:00, 13.16it/s]\n",
            "OVERALL: strict=0.2626, loose micro=0.5519, loose macro=0.6355\n",
            "SEEN: strict=0.6762, loose micro=0.7680, loose macro=0.7885\n",
            "UNSEEN: strict=0.1891, loose micro=0.2468, loose macro=0.2555\n",
            "--epoch 5--\n",
            "100% 86/86 [00:09<00:00,  9.27it/s]\n",
            "train loss 9.9520\n",
            "100% 13/13 [00:01<00:00, 12.79it/s]\n",
            "OVERALL: strict=0.2596, loose micro=0.5456, loose macro=0.6302\n",
            "SEEN: strict=0.6584, loose micro=0.7612, loose macro=0.7836\n",
            "UNSEEN: strict=0.1602, loose micro=0.2247, loose macro=0.2284\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "OVERALL: strict=0.2596, loose micro=0.5456, loose macro=0.6302\n",
        "SEEN: strict=0.6584, loose micro=0.7612, loose macro=0.7836\n",
        "UNSEEN: strict=0.1602, loose micro=0.2247, loose macro=0.2284\n",
        "\n",
        "\"\"\"\n",
        "! python train.py --dataset bbn --label_encoder_type otyper --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC_-VL9Ne7ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc6fea7-f1ef-46f9-ea60-31cd4beb6f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85545it [00:05, 15374.85it/s]\n",
            "12349it [00:01, 10778.16it/s]\n",
            "2196017it [00:44, 48902.19it/s]\n",
            "2196017it [00:31, 69328.26it/s]\n",
            "dataset: bbn\n",
            "label encoder: dzet\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 86/86 [00:25<00:00,  3.40it/s]\n",
            "train loss 23.7143\n",
            "100% 13/13 [00:02<00:00,  4.64it/s]\n",
            "OVERALL: strict=0.2309, loose micro=0.2221, loose macro=0.2745\n",
            "SEEN: strict=0.2693, loose micro=0.2991, loose macro=0.2955\n",
            "UNSEEN: strict=0.0088, loose micro=0.0089, loose macro=0.0089\n",
            "--epoch 2--\n",
            "100% 86/86 [00:17<00:00,  4.78it/s]\n",
            "train loss 14.9306\n",
            "100% 13/13 [00:01<00:00,  9.52it/s]\n",
            "OVERALL: strict=0.2467, loose micro=0.4984, loose macro=0.5437\n",
            "SEEN: strict=0.5375, loose micro=0.6529, loose macro=0.6643\n",
            "UNSEEN: strict=0.0391, loose micro=0.0406, loose macro=0.0402\n",
            "--epoch 3--\n",
            "100% 86/86 [00:17<00:00,  4.86it/s]\n",
            "train loss 12.7331\n",
            "100% 13/13 [00:02<00:00,  5.23it/s]\n",
            "OVERALL: strict=0.2522, loose micro=0.5684, loose macro=0.6215\n",
            "SEEN: strict=0.6646, loose micro=0.7564, loose macro=0.7761\n",
            "UNSEEN: strict=0.1927, loose micro=0.1934, loose macro=0.1958\n",
            "--epoch 4--\n",
            "100% 86/86 [00:17<00:00,  4.84it/s]\n",
            "train loss 11.8043\n",
            "100% 13/13 [00:01<00:00,  9.94it/s]\n",
            "OVERALL: strict=0.2606, loose micro=0.5580, loose macro=0.6166\n",
            "SEEN: strict=0.6409, loose micro=0.7443, loose macro=0.7640\n",
            "UNSEEN: strict=0.2638, loose micro=0.2699, loose macro=0.2738\n",
            "--epoch 5--\n",
            "100% 86/86 [00:19<00:00,  4.48it/s]\n",
            "train loss 11.2765\n",
            "100% 13/13 [00:01<00:00,  9.97it/s]\n",
            "OVERALL: strict=0.2631, loose micro=0.5604, loose macro=0.6267\n",
            "SEEN: strict=0.6603, loose micro=0.7569, loose macro=0.7767\n",
            "UNSEEN: strict=0.2033, loose micro=0.2164, loose macro=0.2210\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "OVERALL: strict=0.2608, loose micro=0.5270, loose macro=0.6112\n",
        "SEEN: strict=0.6220, loose micro=0.7337, loose macro=0.7548\n",
        "UNSEEN: strict=0.2031, loose micro=0.2241, loose macro=0.2355\n",
        "\n",
        "\"\"\"\n",
        "! python train.py --dataset bbn --label_encoder_type dzet --seed 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FGET onto notes"
      ],
      "metadata": {
        "id": "DoibuplUJUbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --dataset ontonotes --label_encoder_type trgcn --seed 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbudz-T5JZ1v",
        "outputId": "cf6d743e-bc98-4aea-b993-1d7eb2cf6602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220398it [00:13, 15778.18it/s]\n",
            "9604it [00:00, 28390.15it/s]\n",
            "100% 230002/230002 [00:02<00:00, 98272.10it/s]\n",
            "2196017it [00:45, 48219.38it/s]\n",
            "dataset: ontonotes\n",
            "label encoder: trgcn\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 221/221 [01:36<00:00,  2.28it/s]\n",
            "train loss 44.7514\n",
            "100% 10/10 [00:04<00:00,  2.33it/s]\n",
            "OVERALL: strict=0.4242, loose micro=0.4531, loose macro=0.5426\n",
            "SEEN: strict=0.4242, loose micro=0.4681, loose macro=0.5443\n",
            "UNSEEN: strict=0.0026, loose micro=0.0049, loose macro=0.0036\n",
            "--epoch 2--\n",
            "100% 221/221 [01:28<00:00,  2.50it/s]\n",
            "train loss 30.1008\n",
            "100% 10/10 [00:04<00:00,  2.41it/s]\n",
            "OVERALL: strict=0.4348, loose micro=0.5140, loose macro=0.6039\n",
            "SEEN: strict=0.4384, loose micro=0.5363, loose macro=0.6081\n",
            "UNSEEN: strict=0.0281, loose micro=0.0290, loose macro=0.0294\n",
            "--epoch 3--\n",
            "100% 221/221 [01:32<00:00,  2.39it/s]\n",
            "train loss 26.4081\n",
            "100% 10/10 [00:04<00:00,  2.45it/s]\n",
            "OVERALL: strict=0.4213, loose micro=0.5391, loose macro=0.6230\n",
            "SEEN: strict=0.4488, loose micro=0.5749, loose macro=0.6374\n",
            "UNSEEN: strict=0.0691, loose micro=0.0808, loose macro=0.0806\n",
            "--epoch 4--\n",
            "100% 221/221 [01:25<00:00,  2.58it/s]\n",
            "train loss 24.7638\n",
            "100% 10/10 [00:04<00:00,  2.43it/s]\n",
            "OVERALL: strict=0.4011, loose micro=0.5251, loose macro=0.5997\n",
            "SEEN: strict=0.4367, loose micro=0.5615, loose macro=0.6160\n",
            "UNSEEN: strict=0.0895, loose micro=0.0956, loose macro=0.0976\n",
            "--epoch 5--\n",
            "100% 221/221 [01:32<00:00,  2.39it/s]\n",
            "train loss 23.5553\n",
            "100% 10/10 [00:04<00:00,  2.47it/s]\n",
            "OVERALL: strict=0.4300, loose micro=0.5644, loose macro=0.6370\n",
            "SEEN: strict=0.4640, loose micro=0.5959, loose macro=0.6501\n",
            "UNSEEN: strict=0.1100, loose micro=0.1138, loose macro=0.1171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --dataset ontonotes --label_encoder_type gcnz --seed 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gchNqwJhJZ4V",
        "outputId": "c58afa5f-7b7a-484f-ed12-b6ca2b748a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220398it [00:14, 15611.71it/s]\n",
            "9604it [00:00, 28129.88it/s]\n",
            "2196017it [00:50, 43285.00it/s]\n",
            "dataset: ontonotes\n",
            "label encoder: gcnz\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 221/221 [00:39<00:00,  5.53it/s]\n",
            "train loss 40.8909\n",
            "100% 10/10 [00:01<00:00,  8.92it/s]\n",
            "OVERALL: strict=0.3891, loose micro=0.4772, loose macro=0.5614\n",
            "SEEN: strict=0.4177, loose micro=0.5193, loose macro=0.5827\n",
            "UNSEEN: strict=0.0563, loose micro=0.0611, loose macro=0.0615\n",
            "--epoch 2--\n",
            "100% 221/221 [00:33<00:00,  6.51it/s]\n",
            "train loss 27.2272\n",
            "100% 10/10 [00:00<00:00, 11.44it/s]\n",
            "OVERALL: strict=0.4409, loose micro=0.5441, loose macro=0.6277\n",
            "SEEN: strict=0.4545, loose micro=0.5737, loose macro=0.6383\n",
            "UNSEEN: strict=0.1483, loose micro=0.1626, loose macro=0.1649\n",
            "--epoch 3--\n",
            "100% 221/221 [00:34<00:00,  6.37it/s]\n",
            "train loss 24.8904\n",
            "100% 10/10 [00:00<00:00, 11.28it/s]\n",
            "OVERALL: strict=0.3965, loose micro=0.5309, loose macro=0.6025\n",
            "SEEN: strict=0.4360, loose micro=0.5629, loose macro=0.6165\n",
            "UNSEEN: strict=0.1688, loose micro=0.1966, loose macro=0.1989\n",
            "--epoch 4--\n",
            "100% 221/221 [00:33<00:00,  6.57it/s]\n",
            "train loss 23.6855\n",
            "100% 10/10 [00:00<00:00, 11.67it/s]\n",
            "OVERALL: strict=0.3948, loose micro=0.5262, loose macro=0.5918\n",
            "SEEN: strict=0.4227, loose micro=0.5548, loose macro=0.6044\n",
            "UNSEEN: strict=0.2455, loose micro=0.2733, loose macro=0.2773\n",
            "--epoch 5--\n",
            "100% 221/221 [00:31<00:00,  7.08it/s]\n",
            "train loss 22.8361\n",
            "100% 10/10 [00:00<00:00, 11.45it/s]\n",
            "OVERALL: strict=0.4066, loose micro=0.5515, loose macro=0.6247\n",
            "SEEN: strict=0.4476, loose micro=0.5878, loose macro=0.6386\n",
            "UNSEEN: strict=0.1893, loose micro=0.2389, loose macro=0.2384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --dataset ontonotes --label_encoder_type sgcn --seed 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhtve_g0JZ65",
        "outputId": "4c060d96-097f-4e33-a731-74d140d6bba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220398it [00:14, 15449.33it/s]\n",
            "9604it [00:00, 27093.51it/s]\n",
            "2196017it [00:49, 44081.80it/s]\n",
            "dataset: ontonotes\n",
            "label encoder: sgcn\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 221/221 [00:39<00:00,  5.56it/s]\n",
            "train loss 40.6152\n",
            "100% 10/10 [00:01<00:00,  9.00it/s]\n",
            "OVERALL: strict=0.3995, loose micro=0.4925, loose macro=0.5683\n",
            "SEEN: strict=0.3996, loose micro=0.5088, loose macro=0.5711\n",
            "UNSEEN: strict=0.1023, loose micro=0.1275, loose macro=0.1245\n",
            "--epoch 2--\n",
            "100% 221/221 [00:34<00:00,  6.38it/s]\n",
            "train loss 27.3750\n",
            "100% 10/10 [00:01<00:00,  7.22it/s]\n",
            "OVERALL: strict=0.4577, loose micro=0.5637, loose macro=0.6458\n",
            "SEEN: strict=0.4594, loose micro=0.5824, loose macro=0.6493\n",
            "UNSEEN: strict=0.2327, loose micro=0.2454, loose macro=0.2513\n",
            "--epoch 3--\n",
            "100% 221/221 [00:33<00:00,  6.58it/s]\n",
            "train loss 25.0496\n",
            "100% 10/10 [00:00<00:00, 11.39it/s]\n",
            "OVERALL: strict=0.4222, loose micro=0.5482, loose macro=0.6176\n",
            "SEEN: strict=0.4374, loose micro=0.5700, loose macro=0.6243\n",
            "UNSEEN: strict=0.2558, loose micro=0.2704, loose macro=0.2762\n",
            "--epoch 4--\n",
            "100% 221/221 [00:33<00:00,  6.51it/s]\n",
            "train loss 23.6471\n",
            "100% 10/10 [00:00<00:00, 11.34it/s]\n",
            "OVERALL: strict=0.4136, loose micro=0.5408, loose macro=0.6063\n",
            "SEEN: strict=0.4319, loose micro=0.5630, loose macro=0.6138\n",
            "UNSEEN: strict=0.2788, loose micro=0.3058, loose macro=0.3105\n",
            "--epoch 5--\n",
            "100% 221/221 [00:31<00:00,  7.05it/s]\n",
            "train loss 22.8336\n",
            "100% 10/10 [00:00<00:00, 11.30it/s]\n",
            "OVERALL: strict=0.4063, loose micro=0.5514, loose macro=0.6179\n",
            "SEEN: strict=0.4388, loose micro=0.5802, loose macro=0.6296\n",
            "UNSEEN: strict=0.2251, loose micro=0.2585, loose macro=0.2606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --dataset ontonotes --label_encoder_type dgp --seed 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQk7CmqAJZ9S",
        "outputId": "4b270083-103c-4246-b750-d35e3de2e283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220398it [00:14, 15712.37it/s]\n",
            "9604it [00:00, 27987.24it/s]\n",
            "2196017it [00:50, 43887.75it/s]\n",
            "edges_set [82115, 75850, 78502, 81000, 83954, 84148, 78505, 65764, 45318, 29248, 18202, 10419, 5829, 3239, 1821, 972, 524, 183, 30]\n",
            "edges_set [82115, 75850, 78502, 81000, 428156]\n",
            "/content/nayak-tmlr22-code/fget/utils/common.py:165: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n",
            "dataset: ontonotes\n",
            "label encoder: dgp\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 221/221 [01:51<00:00,  1.98it/s]\n",
            "train loss 43.0584\n",
            "100% 10/10 [00:02<00:00,  3.78it/s]\n",
            "OVERALL: strict=0.4113, loose micro=0.4435, loose macro=0.5314\n",
            "SEEN: strict=0.4279, loose micro=0.4935, loose macro=0.5690\n",
            "UNSEEN: strict=0.0051, loose micro=0.0074, loose macro=0.0064\n",
            "--epoch 2--\n",
            "100% 221/221 [01:42<00:00,  2.16it/s]\n",
            "train loss 29.5429\n",
            "100% 10/10 [00:02<00:00,  4.18it/s]\n",
            "OVERALL: strict=0.4355, loose micro=0.5336, loose macro=0.6222\n",
            "SEEN: strict=0.4493, loose micro=0.5666, loose macro=0.6349\n",
            "UNSEEN: strict=0.0128, loose micro=0.0148, loose macro=0.0141\n",
            "--epoch 3--\n",
            "100% 221/221 [01:43<00:00,  2.13it/s]\n",
            "train loss 26.5516\n",
            "100% 10/10 [00:02<00:00,  4.10it/s]\n",
            "OVERALL: strict=0.4135, loose micro=0.5285, loose macro=0.6149\n",
            "SEEN: strict=0.4362, loose micro=0.5681, loose macro=0.6302\n",
            "UNSEEN: strict=0.0077, loose micro=0.0098, loose macro=0.0089\n",
            "--epoch 4--\n",
            "100% 221/221 [01:42<00:00,  2.16it/s]\n",
            "train loss 25.2370\n",
            "100% 10/10 [00:02<00:00,  4.14it/s]\n",
            "OVERALL: strict=0.4116, loose micro=0.5434, loose macro=0.6185\n",
            "SEEN: strict=0.4402, loose micro=0.5721, loose macro=0.6297\n",
            "UNSEEN: strict=0.0128, loose micro=0.0197, loose macro=0.0180\n",
            "--epoch 5--\n",
            "100% 221/221 [01:42<00:00,  2.16it/s]\n",
            "train loss 24.1369\n",
            "100% 10/10 [00:02<00:00,  4.17it/s]\n",
            "OVERALL: strict=0.3878, loose micro=0.5307, loose macro=0.5993\n",
            "SEEN: strict=0.4255, loose micro=0.5626, loose macro=0.6130\n",
            "UNSEEN: strict=0.0077, loose micro=0.0197, loose macro=0.0166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --dataset ontonotes --label_encoder_type otyper --seed 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnm7oW1hJZ_X",
        "outputId": "1e6edbff-cdff-44b8-e8f8-8b0fc1a36836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220398it [00:13, 15752.11it/s]\n",
            "9604it [00:00, 29099.59it/s]\n",
            "2196017it [00:50, 43599.24it/s]\n",
            "2196017it [00:25, 86908.05it/s]\n",
            "dataset: ontonotes\n",
            "label encoder: otyper\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 221/221 [00:33<00:00,  6.65it/s]\n",
            "train loss 35.0678\n",
            "100% 10/10 [00:01<00:00,  9.69it/s]\n",
            "OVERALL: strict=0.4632, loose micro=0.5718, loose macro=0.6527\n",
            "SEEN: strict=0.4644, loose micro=0.5877, loose macro=0.6559\n",
            "UNSEEN: strict=0.0384, loose micro=0.0418, loose macro=0.0417\n",
            "--epoch 2--\n",
            "100% 221/221 [00:26<00:00,  8.29it/s]\n",
            "train loss 24.9653\n",
            "100% 10/10 [00:00<00:00, 12.64it/s]\n",
            "OVERALL: strict=0.4413, loose micro=0.5603, loose macro=0.6254\n",
            "SEEN: strict=0.4642, loose micro=0.5944, loose macro=0.6484\n",
            "UNSEEN: strict=0.0639, loose micro=0.0655, loose macro=0.0672\n",
            "--epoch 3--\n",
            "100% 221/221 [00:24<00:00,  8.91it/s]\n",
            "train loss 23.0131\n",
            "100% 10/10 [00:01<00:00,  8.10it/s]\n",
            "OVERALL: strict=0.4080, loose micro=0.5392, loose macro=0.5998\n",
            "SEEN: strict=0.4460, loose micro=0.5871, loose macro=0.6366\n",
            "UNSEEN: strict=0.0921, loose micro=0.0898, loose macro=0.0934\n",
            "--epoch 4--\n",
            "100% 221/221 [00:26<00:00,  8.42it/s]\n",
            "train loss 22.1071\n",
            "100% 10/10 [00:00<00:00, 12.69it/s]\n",
            "OVERALL: strict=0.4065, loose micro=0.5351, loose macro=0.5981\n",
            "SEEN: strict=0.4417, loose micro=0.5814, loose macro=0.6307\n",
            "UNSEEN: strict=0.1151, loose micro=0.1110, loose macro=0.1164\n",
            "--epoch 5--\n",
            "100% 221/221 [00:23<00:00,  9.35it/s]\n",
            "train loss 21.5984\n",
            "100% 10/10 [00:00<00:00, 12.67it/s]\n",
            "OVERALL: strict=0.4224, loose micro=0.5514, loose macro=0.6154\n",
            "SEEN: strict=0.4544, loose micro=0.5946, loose macro=0.6446\n",
            "UNSEEN: strict=0.1202, loose micro=0.1184, loose macro=0.1235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --dataset ontonotes --label_encoder_type dzet --seed 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssHbIOCgJaBb",
        "outputId": "9cee43e4-86ac-45e5-b896-909e74b465f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220398it [00:13, 15757.64it/s]\n",
            "9604it [00:00, 27327.27it/s]\n",
            "2196017it [00:45, 48743.98it/s]\n",
            "2196017it [00:26, 82944.40it/s]\n",
            "dataset: ontonotes\n",
            "label encoder: dzet\n",
            "seed: 0\n",
            "--epoch 1--\n",
            "100% 221/221 [01:12<00:00,  3.07it/s]\n",
            "train loss 38.6093\n",
            "100% 10/10 [00:01<00:00,  6.83it/s]\n",
            "OVERALL: strict=0.4790, loose micro=0.5630, loose macro=0.6543\n",
            "SEEN: strict=0.4791, loose micro=0.5842, loose macro=0.6588\n",
            "UNSEEN: strict=0.0307, loose micro=0.0319, loose macro=0.0320\n",
            "--epoch 2--\n",
            "100% 221/221 [01:08<00:00,  3.22it/s]\n",
            "train loss 27.1209\n",
            "100% 10/10 [00:01<00:00,  8.52it/s]\n",
            "OVERALL: strict=0.4926, loose micro=0.5854, loose macro=0.6631\n",
            "SEEN: strict=0.4938, loose micro=0.6020, loose macro=0.6663\n",
            "UNSEEN: strict=0.1355, loose micro=0.1308, loose macro=0.1369\n",
            "--epoch 3--\n",
            "100% 221/221 [01:05<00:00,  3.35it/s]\n",
            "train loss 25.0596\n",
            "100% 10/10 [00:01<00:00,  8.67it/s]\n",
            "OVERALL: strict=0.4140, loose micro=0.5413, loose macro=0.6005\n",
            "SEEN: strict=0.4158, loose micro=0.5570, loose macro=0.6045\n",
            "UNSEEN: strict=0.1586, loose micro=0.1516, loose macro=0.1599\n",
            "--epoch 4--\n",
            "100% 221/221 [01:08<00:00,  3.23it/s]\n",
            "train loss 23.9709\n",
            "100% 10/10 [00:01<00:00,  8.14it/s]\n",
            "OVERALL: strict=0.4328, loose micro=0.5549, loose macro=0.6158\n",
            "SEEN: strict=0.4362, loose micro=0.5723, loose macro=0.6205\n",
            "UNSEEN: strict=0.0870, loose micro=0.0837, loose macro=0.0883\n",
            "--epoch 5--\n",
            "100% 221/221 [01:05<00:00,  3.36it/s]\n",
            "train loss 23.3425\n",
            "100% 10/10 [00:01<00:00,  8.26it/s]\n",
            "OVERALL: strict=0.4177, loose micro=0.5600, loose macro=0.6189\n",
            "SEEN: strict=0.4213, loose micro=0.5770, loose macro=0.6235\n",
            "UNSEEN: strict=0.0997, loose micro=0.0958, loose macro=0.1011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2DdbFSte-MB"
      },
      "source": [
        "# Object Classification Dataset "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd nayak-tmlr22-code"
      ],
      "metadata": {
        "id": "alSXn_QnmjFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NwubhyXfB76",
        "outputId": "3175a432-81e0-4c05-a5f8-c148cf16ed65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# come out from intent classi if needed\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IRCWbuO2fB-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d04287-3b70-4f9e-bb1c-07ab6d51a31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'object_classification'\n",
            "/content\n",
            "mkdir: cannot create directory ‘materials/datasets’: No such file or directory\n",
            "mkdir: cannot create directory ‘materials/datasets/imagenet’: No such file or directory\n",
            "mkdir: cannot create directory ‘materials/datasets/awa2’: No such file or directory\n",
            "mkdir: cannot create directory ‘materials/datasets/apy’: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# make datset folder for ontonotes and bbn\n",
        "%cd object_classification\n",
        "! mkdir data\n",
        "! mkdir data/subgraphs\n",
        "! mkdir materials/datasets\n",
        "! mkdir materials/datasets/imagenet\n",
        "! mkdir materials/datasets/awa2\n",
        "! mkdir materials/datasets/apy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0oHeC5YHa7aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11f4d13-734d-49fd-9d28-d39c1df7f9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13nqh3S65xDH7wUZ0Qns9KNCjdbwHRrhY\n",
            "To: /content/ilsvrc_graph.zip\n",
            "100% 475M/475M [00:08<00:00, 58.6MB/s]\n",
            "Archive:  data/subgraphs/ilsvrc_graph.zip\n",
            "   creating: data/subgraphs/ilsvrc_graph/\n",
            "  inflating: data/subgraphs/ilsvrc_graph/params.pkl  \n",
            "  inflating: data/subgraphs/ilsvrc_graph/graph_data.pt  \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P-bhGk_xtHmBsUB33oMP__5WeE4HKOsX\n",
            "To: /content/awa2_graph.zip\n",
            "100% 201M/201M [00:06<00:00, 32.3MB/s]\n",
            "Archive:  data/subgraphs/awa2_graph.zip\n",
            "   creating: data/subgraphs/awa2_graph/\n",
            "  inflating: data/subgraphs/awa2_graph/params.pkl  \n",
            "  inflating: data/subgraphs/awa2_graph/graph_data.pt  \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wOEf7OEemV1b929Wd8gRmlTAE9UTssEh\n",
            "To: /content/apy_graph.zip\n",
            "100% 319M/319M [00:08<00:00, 37.3MB/s]\n",
            "Archive:  data/subgraphs/apy_graph.zip\n",
            "   creating: data/subgraphs/apy_graph/\n",
            "  inflating: data/subgraphs/apy_graph/params.pkl  \n",
            "  inflating: data/subgraphs/apy_graph/graph_data.pt  \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hCF8vVCEpVfcJ-GREsGlaBevmPEnAq7X\n",
            "To: /content/wordnet_graph.zip\n",
            "100% 88.4M/88.4M [00:02<00:00, 35.2MB/s]\n",
            "Archive:  data/subgraphs/wordnet_graph.zip\n",
            "   creating: data/subgraphs/wordnet_graph/\n",
            "  inflating: data/subgraphs/wordnet_graph/params.pkl  \n",
            "  inflating: data/subgraphs/wordnet_graph/graph_data.pt  \n"
          ]
        }
      ],
      "source": [
        "# download knowledge graphs\n",
        "# ilsvrc_graph.zip https://drive.google.com/file/d/13nqh3S65xDH7wUZ0Qns9KNCjdbwHRrhY/view?usp=sharing\n",
        "# awa2_graph.zip https://drive.google.com/file/d/1P-bhGk_xtHmBsUB33oMP__5WeE4HKOsX/view?usp=sharing\n",
        "# apy_graph.zip https://drive.google.com/file/d/1wOEf7OEemV1b929Wd8gRmlTAE9UTssEh/view?usp=sharing\n",
        "# wordnet_graph.zip https://drive.google.com/file/d/1hCF8vVCEpVfcJ-GREsGlaBevmPEnAq7X/view?usp=sharing\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=13nqh3S65xDH7wUZ0Qns9KNCjdbwHRrhY\n",
        "! mv ilsvrc_graph.zip data/subgraphs/ilsvrc_graph.zip\n",
        "! unzip -o data/subgraphs/ilsvrc_graph.zip -d data/subgraphs/\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=1P-bhGk_xtHmBsUB33oMP__5WeE4HKOsX\n",
        "! mv awa2_graph.zip data/subgraphs/awa2_graph.zip\n",
        "! unzip -o data/subgraphs/awa2_graph.zip -d data/subgraphs/\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=1wOEf7OEemV1b929Wd8gRmlTAE9UTssEh\n",
        "! mv apy_graph.zip data/subgraphs/apy_graph.zip\n",
        "! unzip -o data/subgraphs/apy_graph.zip -d data/subgraphs/\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=1hCF8vVCEpVfcJ-GREsGlaBevmPEnAq7X\n",
        "! mv wordnet_graph.zip data/subgraphs/wordnet_graph.zip\n",
        "! unzip -o data/subgraphs/wordnet_graph.zip -d data/subgraphs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fx47pJWWfCBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f02d84e-6380-41c9-b9c6-fd2e0cf3d338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kGmMyZgowhMzdU9oEq8tapCYnTQJanns\n",
            "To: /content/dense_graph.json\n",
            "100% 191M/191M [00:02<00:00, 72.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EVmj6hjg9sD9LlQEVse1uaYdL0Rbm5BM\n",
            "To: /content/induced_graph.json\n",
            "100% 189M/189M [00:05<00:00, 36.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download model for baseline\n",
        "# https://drive.google.com/file/d/1kGmMyZgowhMzdU9oEq8tapCYnTQJanns/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1kGmMyZgowhMzdU9oEq8tapCYnTQJanns\n",
        "! mv dense_graph.json data/dense_graph.json\n",
        "# https://drive.google.com/file/d/1EVmj6hjg9sD9LlQEVse1uaYdL0Rbm5BM/view?usp=sharing\n",
        "! gdown https://drive.google.com/uc?id=1EVmj6hjg9sD9LlQEVse1uaYdL0Rbm5BM\n",
        "! mv induced_graph.json data/induced_graph.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wq8xK4RYfCDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa611f2a-c1dd-4a15-ddc5-be4f02e87a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-22 11:28:46--  https://cvml.ist.ac.at/AwA2/AwA2-data.zip\n",
            "Resolving cvml.ist.ac.at (cvml.ist.ac.at)... 81.223.84.195\n",
            "Connecting to cvml.ist.ac.at (cvml.ist.ac.at)|81.223.84.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13923888724 (13G) [application/zip]\n",
            "Saving to: ‘AwA2-data.zip’\n",
            "\n",
            "AwA2-data.zip       100%[===================>]  12.97G  7.62MB/s    in 38m 45s \n",
            "\n",
            "2022-10-22 12:07:33 (5.71 MB/s) - ‘AwA2-data.zip’ saved [13923888724/13923888724]\n",
            "\n",
            "mv: cannot move 'AwA2-data.zip' to 'materials/datasets/awa2/': No such file or directory\n",
            "unzip:  cannot find or open materials/datasets/awa2/AwA2-data.zip, materials/datasets/awa2/AwA2-data.zip.zip or materials/datasets/awa2/AwA2-data.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# awa2 dataset download\n",
        "# awa2 https://cvml.ist.ac.at/AwA2/AwA2-data.zip\n",
        "! wget https://cvml.ist.ac.at/AwA2/AwA2-data.zip\n",
        "! mv AwA2-data.zip materials/datasets/awa2/\n",
        "! unzip -o -j materials/datasets/awa2/AwA2-data.zip -d materials/datasets/awa2/\n",
        "\n",
        "# download datasets \n",
        "# image net was unavailable for direct download\n",
        "\n",
        "# apy http://vision.cs.uiuc.edu/attributes/ayahoo_test_images.tar.gz\n",
        "# ! wget http://vision.cs.uiuc.edu/attributes/ayahoo_test_images.tar.gz\n",
        "# ! mv ayahoo_test_images.tar.gz materials/datasets/apy/\n",
        "# ! unzip -o -j materials/datasets/apy/ayahoo_test_images.tar.gz -d materials/datasets/apy/\n",
        "\n",
        "# # apy http://host.robots.ox.ac.uk/pascal/VOC/voc2008/VOCtrainval_14-Jul-2008.tar\n",
        "# ! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2008/VOCtrainval_14-Jul-2008.tar\n",
        "# ! mv VOCtrainval_14-Jul-2008.tar materials/datasets/apy/\n",
        "# ! unzip -o -j materials/datasets/apy/VOCtrainval_14-Jul-2008.tar -d materials/datasets/apy/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUXr2JJkkF9Y"
      },
      "source": [
        "## Set up and Run AWA2 Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "foSCUbqIfCFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d345ac-d9d9-49ca-bfdc-e94facfde340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'materials'\n",
            "/content\n",
            "python3: can't open file 'gbu_awa2.py': [Errno 2] No such file or directory\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "%cd materials\n",
        "! python gbu_awa2.py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aHTWYClZfCIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b98c81-e77c-440b-ebd0-961e2f652ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! python train.py --label_encoder trgcn --max-epoch 1000 --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi9yo0POfCKW"
      },
      "outputs": [],
      "source": [
        "! python train.py --label_encoder gcnz --max-epoch 1000 --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jH0tUwiT-rw"
      },
      "outputs": [],
      "source": [
        "! python train.py --label_encoder sgcn --max-epoch 1000 --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0DHkGMdT-xQ"
      },
      "outputs": [],
      "source": [
        "! python train.py --label_encoder dgp --max-epoch 1000 --seed 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH8nqwVvT-4F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxKlb-2S0Ck2"
      },
      "source": [
        "## APY Setup and experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYWwB43XfCyS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcBASvcd0FUF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjayPSBF0FWm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-yBTt8p0FY8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B6FJqVA0Fa_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnipBKUCfC_M"
      },
      "source": [
        "# trying to set up some changes to train.py but there was no need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yepzlka4zV0"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# Set up file location to go into to run experiments \n",
        "# \"\"\"\n",
        "# import os\n",
        "# import sys\n",
        "# M_DIR_PATH = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "# INTENT_PATH = M_DIR_PATH + '/intent_classification'\n",
        "# OBJECT_PATH = M_DIR_PATH + '/object_classification'\n",
        "# FGET_PATH = M_DIR_PATH + '/fget'\n",
        "# os.chdir(INTENT_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFAWHYOdg9UI"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# we want to run the same experiment several times while \n",
        "# keeping the result, so i added the intent classification folder\n",
        "# to set up experiment \n",
        "# I don't really liked nayak way of experimentation since it's just\n",
        "# 1 experiment without creating results for me in file.\n",
        "# so i become very hacky and basically set working directory to be\n",
        "# in intent classification and then do main and train_epoch function\n",
        "# so that they return me results and run the experiment multiple times\n",
        "\n",
        "# yes this is hacky but I have 1 week left to do this \n",
        "# \"\"\"\n",
        "# from train import *\n",
        "# def train_epochs_2(model, iterator, optimizer, datasets, options, epochs=10):\n",
        "#     \"\"\"The function is used to train the model for a given number of epochs\"\"\"\n",
        "#     val_loss = []\n",
        "\n",
        "#     train_dataset, dev_dataset, test_dataset = tuple(datasets)\n",
        "#     if options[\"label_encoder_type\"] in [\n",
        "#         \"gcn\",\n",
        "#         \"gat\",\n",
        "#         \"rgcn\",\n",
        "#         \"lstm\",\n",
        "#         \"trgcn\",\n",
        "#     ]:\n",
        "#         train_graph, dev_graph, test_graph = get_graph(options[\"graph_path\"])\n",
        "#         # move to device\n",
        "#         train_graph.to(options[\"device\"])\n",
        "#         dev_graph.to(options[\"device\"])\n",
        "#         test_graph.to(options[\"device\"])\n",
        "#         # get idx\n",
        "#         train_idx = train_graph.get_node_ids(concept_maps[\"train\"])\n",
        "#         dev_idx = train_graph.get_node_ids(concept_maps[\"dev\"])\n",
        "#         test_idx = train_graph.get_node_ids(concept_maps[\"test\"])\n",
        "#     else:\n",
        "#         train_graph = None\n",
        "#         dev_graph = None\n",
        "#         test_graph = None\n",
        "#         wn_mapping = pd.read_csv(\n",
        "#             os.path.join(DIR_PATH, \"misc_data/snips_mapping.csv\")\n",
        "#         )\n",
        "#         graph = json.load(\n",
        "#             open(os.path.join(DIR_PATH, \"data/induced_graph.json\"), \"r\")\n",
        "#         )\n",
        "#         wnids = graph[\"wnids\"]\n",
        "#         wnid_to_idx = dict([(wnid, idx) for idx, wnid in enumerate(wnids)])\n",
        "#         label_idx = [wnid_to_idx[wn_mapping[\"wnid\"][i]] for i in range(7)]\n",
        "#         train_idx = label_idx[:3]\n",
        "#         dev_idx = label_idx[3:5]\n",
        "#         test_idx = label_idx[5:]\n",
        "\n",
        "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         print(f\"**** Epoch {epoch} ****\")\n",
        "#         model, optimizer = train_model(\n",
        "#             model,\n",
        "#             train_dataset,\n",
        "#             iterator,\n",
        "#             optimizer,\n",
        "#             train_graph,\n",
        "#             torch.tensor(train_idx).to(options[\"device\"]),\n",
        "#         )\n",
        "\n",
        "#         loss = compute_loss(\n",
        "#             model,\n",
        "#             dev_dataset,\n",
        "#             iterator,\n",
        "#             dev_graph,\n",
        "#             torch.tensor(dev_idx).to(options[\"device\"]),\n",
        "#         )\n",
        "#         print(f\"Val Loss {loss}\")\n",
        "\n",
        "#         if epoch > 0:\n",
        "#             if loss < min(val_loss):\n",
        "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#         else:\n",
        "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "#         val_loss.append(loss)\n",
        "\n",
        "#         test_model(\n",
        "#             model,\n",
        "#             test_dataset,\n",
        "#             iterator,\n",
        "#             test_graph,\n",
        "#             torch.tensor(test_idx).to(options[\"device\"]),\n",
        "#         )\n",
        "\n",
        "#     save_path = get_save_path(model.options[\"model_path\"], options)\n",
        "#     torch.save(best_model_wts, save_path)\n",
        "\n",
        "#     print(\"done with model training\")\n",
        "#     print(\"loading best model\")\n",
        "\n",
        "#     model.load_state_dict(best_model_wts)\n",
        "#     result = test_model(\n",
        "#         model,\n",
        "#         test_dataset,\n",
        "#         iterator,\n",
        "#         test_graph,\n",
        "#         torch.tensor(test_idx).to(options[\"device\"]),\n",
        "#     )\n",
        "#     print(\"done!\")\n",
        "#     return (\n",
        "#       model,\n",
        "#       test_dataset,\n",
        "#       iterator,\n",
        "#       test_graph,\n",
        "#       torch.tensor(test_idx).to(options[\"device\"]),\n",
        "#       result \n",
        "#     )\n",
        "# def main_loop(label_encoder_type, \n",
        "#               seed=0, \n",
        "#               lr=0.001, \n",
        "#               decay=1e-05, \n",
        "#               gpu=0, \n",
        "#               count=30):\n",
        "#     \"\"\"\n",
        "#     The function is used to setup and train the model for the dataset\n",
        "#     and the encoder type; the function trains a bilinear model\n",
        "#     with a bilstm text encoder with the label encoder mentioned in the\n",
        "#     parameter\n",
        "#     \"\"\"\n",
        "#     results = []\n",
        "#     for i in range(count):\n",
        "#       print('run number:', i)\n",
        "#       print(\"*\" * 20)\n",
        "#       print(\"Training Details\")\n",
        "#       print(\"DATASET: \", \"snips\")\n",
        "#       print(\"ENCODER: \", label_encoder_type)\n",
        "#       print(\"*\" * 20)\n",
        "\n",
        "#       model_path = os.path.join(DIR_PATH, \"data/models/snips\")\n",
        "\n",
        "#       # create directory for saving the model\n",
        "#       if not os.path.exists(model_path):\n",
        "#           os.makedirs(model_path)\n",
        "\n",
        "#       set_seed(seed)\n",
        "#       device, cuda_device = init_device(gpu)\n",
        "\n",
        "#       options = {\n",
        "#           \"label_encoder_type\": label_encoder_type,\n",
        "#           \"lr\": lr,\n",
        "#           \"dataset\": \"snips\",\n",
        "#           \"joint_dim\": JOINT_DIM,\n",
        "#           \"decay\": decay,\n",
        "#           \"seed\": seed,\n",
        "#           \"graph_path\": os.path.join(DIR_PATH, \"data/subgraphs/snips_graph\"),\n",
        "#           \"model_path\": model_path,\n",
        "#           \"gpu\": gpu,\n",
        "#           \"device\": device,\n",
        "#           \"cuda_device\": cuda_device,\n",
        "#       }\n",
        "\n",
        "#       # get the vocab and everything else for training the models\n",
        "#       model, iterator, optimizer, datasets = setup(label_encoder_type, options)\n",
        "\n",
        "#       model, dataset, iterator, kg, label_idx, result = train_epochs_2(model, iterator, optimizer, datasets, options, epochs=10)\n",
        "#       results.append(result['unseen_acc'])\n",
        "#       print(results)\n",
        "#     return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3WUd80o9KY-"
      },
      "outputs": [],
      "source": [
        "# trgcn_result = main_loop(label_encoder_type='trgcn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll-fgYPFUpm8"
      },
      "outputs": [],
      "source": [
        "# trgcn_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpdVFDCxFspC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}